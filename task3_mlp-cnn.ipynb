{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOiarERchvwcH+7Z2bbwvJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/lisasimakova/d41d3630a6b5a1313431a91dae94c3d8/mlp-cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обоснование выбора признаков, модели и параметров\n",
        "\n",
        "В качестве признаков использованы дескрипторы Mordred.\n",
        "\n",
        "Для предсказания pIC50 выбрана нейронная сеть (MLP). Эта архитектура подходит для работы с числовыми признаками фиксированной размерности и может выявлять нелинейные зависимости между дескрипторами и целевой переменной. Используется два скрытых слоя с ReLU-активацией и Dropout для борьбы с переобучением.\n",
        "\n",
        "Модель обучается с ранней остановкой по валидационной ошибке, что позволяет предотвратить переобучение без необходимости вручную подбирать число эпох. Используется Adam-оптимизатор и MSELoss как функция ошибки, стандартные для регрессии.\n",
        "\n",
        "Для оценки обобщающей способности применяется 5-кратная кросс-валидация, после чего модель дообучается на всём train+val и тестируется на отложенной выборке."
      ],
      "metadata": {
        "id": "kiYk2ifUP2Il"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlCTQkejZ5mP",
        "outputId": "b5003ec9-f542-49b2-c8a2-a0f0e12a4c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=2.7134\n",
            "Epoch 2: val_loss=1.7722\n",
            "Epoch 3: val_loss=1.5445\n",
            "Epoch 4: val_loss=1.5410\n",
            "Epoch 5: val_loss=1.3890\n",
            "Epoch 6: val_loss=1.3647\n",
            "Epoch 7: val_loss=1.3131\n",
            "Epoch 8: val_loss=1.2601\n",
            "Epoch 9: val_loss=1.2245\n",
            "Epoch 10: val_loss=1.1919\n",
            "Epoch 11: val_loss=1.1661\n",
            "Epoch 12: val_loss=1.1504\n",
            "Epoch 13: val_loss=1.2299\n",
            "Epoch 14: val_loss=1.1238\n",
            "Epoch 15: val_loss=1.0973\n",
            "Epoch 16: val_loss=1.1152\n",
            "Epoch 17: val_loss=1.1330\n",
            "Epoch 18: val_loss=1.0765\n",
            "Epoch 19: val_loss=1.0426\n",
            "Epoch 20: val_loss=1.0907\n",
            "Epoch 21: val_loss=1.0655\n",
            "Epoch 22: val_loss=1.1237\n",
            "Epoch 23: val_loss=1.0530\n",
            "Epoch 24: val_loss=1.1237\n",
            "Epoch 25: val_loss=1.0872\n",
            "Epoch 26: val_loss=1.0750\n",
            "Epoch 27: val_loss=1.0832\n",
            "Epoch 28: val_loss=1.0563\n",
            "Epoch 29: val_loss=1.0315\n",
            "Epoch 30: val_loss=1.1221\n",
            "Epoch 31: val_loss=1.1340\n",
            "Epoch 32: val_loss=1.1890\n",
            "Epoch 33: val_loss=1.0785\n",
            "Epoch 34: val_loss=1.0374\n",
            "Epoch 35: val_loss=1.1646\n",
            "Epoch 36: val_loss=1.0505\n",
            "Epoch 37: val_loss=1.0790\n",
            "Epoch 38: val_loss=1.0745\n",
            "Epoch 39: val_loss=1.2245\n",
            "Early stopping triggered.\n",
            "MAE : 0.7734, RMSE: 1.1066, R²: 0.1764\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=3.0894\n",
            "Epoch 2: val_loss=1.9790\n",
            "Epoch 3: val_loss=1.7847\n",
            "Epoch 4: val_loss=1.6536\n",
            "Epoch 5: val_loss=1.6104\n",
            "Epoch 6: val_loss=1.5640\n",
            "Epoch 7: val_loss=1.5124\n",
            "Epoch 8: val_loss=1.5007\n",
            "Epoch 9: val_loss=1.4347\n",
            "Epoch 10: val_loss=1.3814\n",
            "Epoch 11: val_loss=1.3915\n",
            "Epoch 12: val_loss=1.3338\n",
            "Epoch 13: val_loss=1.3147\n",
            "Epoch 14: val_loss=1.3006\n",
            "Epoch 15: val_loss=1.3407\n",
            "Epoch 16: val_loss=1.3002\n",
            "Epoch 17: val_loss=1.2436\n",
            "Epoch 18: val_loss=1.2537\n",
            "Epoch 19: val_loss=1.2302\n",
            "Epoch 20: val_loss=1.2519\n",
            "Epoch 21: val_loss=1.2154\n",
            "Epoch 22: val_loss=1.2575\n",
            "Epoch 23: val_loss=1.2041\n",
            "Epoch 24: val_loss=1.2331\n",
            "Epoch 25: val_loss=1.2442\n",
            "Epoch 26: val_loss=1.2176\n",
            "Epoch 27: val_loss=1.2595\n",
            "Epoch 28: val_loss=1.2079\n",
            "Epoch 29: val_loss=1.2379\n",
            "Epoch 30: val_loss=1.2227\n",
            "Epoch 31: val_loss=1.1706\n",
            "Epoch 32: val_loss=1.1779\n",
            "Epoch 33: val_loss=1.1981\n",
            "Epoch 34: val_loss=1.1620\n",
            "Epoch 35: val_loss=1.2261\n",
            "Epoch 36: val_loss=1.1698\n",
            "Epoch 37: val_loss=1.1551\n",
            "Epoch 38: val_loss=1.2199\n",
            "Epoch 39: val_loss=1.3356\n",
            "Epoch 40: val_loss=1.1784\n",
            "Epoch 41: val_loss=1.1844\n",
            "Epoch 42: val_loss=1.1759\n",
            "Epoch 43: val_loss=1.2428\n",
            "Epoch 44: val_loss=1.2136\n",
            "Epoch 45: val_loss=1.1183\n",
            "Epoch 46: val_loss=1.1705\n",
            "Epoch 47: val_loss=1.2132\n",
            "Epoch 48: val_loss=1.2149\n",
            "Epoch 49: val_loss=1.1085\n",
            "Epoch 50: val_loss=1.0953\n",
            "Epoch 51: val_loss=1.1530\n",
            "Epoch 52: val_loss=1.2453\n",
            "Epoch 53: val_loss=1.1254\n",
            "Epoch 54: val_loss=1.1812\n",
            "Epoch 55: val_loss=1.1228\n",
            "Epoch 56: val_loss=1.0867\n",
            "Epoch 57: val_loss=1.0836\n",
            "Epoch 58: val_loss=1.0685\n",
            "Epoch 59: val_loss=1.0737\n",
            "Epoch 60: val_loss=1.1708\n",
            "Epoch 61: val_loss=1.0877\n",
            "Epoch 62: val_loss=1.1336\n",
            "Epoch 63: val_loss=1.1723\n",
            "Epoch 64: val_loss=1.1455\n",
            "Epoch 65: val_loss=1.1995\n",
            "Epoch 66: val_loss=1.0952\n",
            "Epoch 67: val_loss=1.0759\n",
            "Epoch 68: val_loss=1.1019\n",
            "Early stopping triggered.\n",
            "MAE : 0.7555, RMSE: 1.0497, R²: 0.3284\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=4.1912\n",
            "Epoch 2: val_loss=2.8341\n",
            "Epoch 3: val_loss=2.5517\n",
            "Epoch 4: val_loss=2.3640\n",
            "Epoch 5: val_loss=2.2504\n",
            "Epoch 6: val_loss=2.1606\n",
            "Epoch 7: val_loss=2.1287\n",
            "Epoch 8: val_loss=2.0386\n",
            "Epoch 9: val_loss=1.9871\n",
            "Epoch 10: val_loss=1.9790\n",
            "Epoch 11: val_loss=1.8999\n",
            "Epoch 12: val_loss=1.8681\n",
            "Epoch 13: val_loss=1.8757\n",
            "Epoch 14: val_loss=1.7816\n",
            "Epoch 15: val_loss=1.7615\n",
            "Epoch 16: val_loss=1.7583\n",
            "Epoch 17: val_loss=1.7650\n",
            "Epoch 18: val_loss=1.6809\n",
            "Epoch 19: val_loss=1.7628\n",
            "Epoch 20: val_loss=1.6826\n",
            "Epoch 21: val_loss=1.5779\n",
            "Epoch 22: val_loss=1.6776\n",
            "Epoch 23: val_loss=1.5294\n",
            "Epoch 24: val_loss=1.5549\n",
            "Epoch 25: val_loss=1.5266\n",
            "Epoch 26: val_loss=1.5570\n",
            "Epoch 27: val_loss=1.5568\n",
            "Epoch 28: val_loss=1.6293\n",
            "Epoch 29: val_loss=1.4171\n",
            "Epoch 30: val_loss=1.4052\n",
            "Epoch 31: val_loss=1.5555\n",
            "Epoch 32: val_loss=1.4715\n",
            "Epoch 33: val_loss=1.4524\n",
            "Epoch 34: val_loss=1.4994\n",
            "Epoch 35: val_loss=1.5071\n",
            "Epoch 36: val_loss=1.4535\n",
            "Epoch 37: val_loss=1.6005\n",
            "Epoch 38: val_loss=1.4272\n",
            "Epoch 39: val_loss=1.4451\n",
            "Epoch 40: val_loss=1.4159\n",
            "Early stopping triggered.\n",
            "MAE : 0.7456, RMSE: 1.1902, R²: 0.1215\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=6.5328\n",
            "Epoch 2: val_loss=5.7448\n",
            "Epoch 3: val_loss=5.3590\n",
            "Epoch 4: val_loss=5.0967\n",
            "Epoch 5: val_loss=5.0755\n",
            "Epoch 6: val_loss=4.8969\n",
            "Epoch 7: val_loss=4.7441\n",
            "Epoch 8: val_loss=4.8297\n",
            "Epoch 9: val_loss=4.8103\n",
            "Epoch 10: val_loss=4.6094\n",
            "Epoch 11: val_loss=4.7113\n",
            "Epoch 12: val_loss=4.7346\n",
            "Epoch 13: val_loss=4.6715\n",
            "Epoch 14: val_loss=4.9838\n",
            "Epoch 15: val_loss=4.6301\n",
            "Epoch 16: val_loss=4.5182\n",
            "Epoch 17: val_loss=4.4370\n",
            "Epoch 18: val_loss=4.4001\n",
            "Epoch 19: val_loss=4.7711\n",
            "Epoch 20: val_loss=4.7210\n",
            "Epoch 21: val_loss=4.9701\n",
            "Epoch 22: val_loss=4.7560\n",
            "Epoch 23: val_loss=4.9603\n",
            "Epoch 24: val_loss=4.9569\n",
            "Epoch 25: val_loss=4.8855\n",
            "Epoch 26: val_loss=4.7924\n",
            "Epoch 27: val_loss=5.1224\n",
            "Epoch 28: val_loss=4.7401\n",
            "Early stopping triggered.\n",
            "MAE : 0.9168, RMSE: 2.1786, R²: -1.9979\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=5.0220\n",
            "Epoch 2: val_loss=3.2630\n",
            "Epoch 3: val_loss=2.7767\n",
            "Epoch 4: val_loss=2.5038\n",
            "Epoch 5: val_loss=2.5222\n",
            "Epoch 6: val_loss=2.3261\n",
            "Epoch 7: val_loss=2.2710\n",
            "Epoch 8: val_loss=2.1883\n",
            "Epoch 9: val_loss=2.1155\n",
            "Epoch 10: val_loss=2.1052\n",
            "Epoch 11: val_loss=2.0832\n",
            "Epoch 12: val_loss=1.9908\n",
            "Epoch 13: val_loss=1.9920\n",
            "Epoch 14: val_loss=1.9863\n",
            "Epoch 15: val_loss=1.9632\n",
            "Epoch 16: val_loss=1.9186\n",
            "Epoch 17: val_loss=1.8545\n",
            "Epoch 18: val_loss=1.9440\n",
            "Epoch 19: val_loss=1.7867\n",
            "Epoch 20: val_loss=1.7579\n",
            "Epoch 21: val_loss=1.7985\n",
            "Epoch 22: val_loss=1.7399\n",
            "Epoch 23: val_loss=1.7333\n",
            "Epoch 24: val_loss=1.7401\n",
            "Epoch 25: val_loss=1.7467\n",
            "Epoch 26: val_loss=1.5860\n",
            "Epoch 27: val_loss=1.7384\n",
            "Epoch 28: val_loss=1.6395\n",
            "Epoch 29: val_loss=1.6410\n",
            "Epoch 30: val_loss=1.7984\n",
            "Epoch 31: val_loss=1.6907\n",
            "Epoch 32: val_loss=1.5659\n",
            "Epoch 33: val_loss=1.6558\n",
            "Epoch 34: val_loss=1.5351\n",
            "Epoch 35: val_loss=1.4799\n",
            "Epoch 36: val_loss=1.4442\n",
            "Epoch 37: val_loss=1.4877\n",
            "Epoch 38: val_loss=1.5505\n",
            "Epoch 39: val_loss=1.4560\n",
            "Epoch 40: val_loss=1.5958\n",
            "Epoch 41: val_loss=1.4487\n",
            "Epoch 42: val_loss=1.4151\n",
            "Epoch 43: val_loss=1.4199\n",
            "Epoch 44: val_loss=1.3804\n",
            "Epoch 45: val_loss=1.4208\n",
            "Epoch 46: val_loss=1.3565\n",
            "Epoch 47: val_loss=1.4647\n",
            "Epoch 48: val_loss=1.4396\n",
            "Epoch 49: val_loss=1.2670\n",
            "Epoch 50: val_loss=1.3069\n",
            "Epoch 51: val_loss=1.3288\n",
            "Epoch 52: val_loss=1.2546\n",
            "Epoch 53: val_loss=1.3279\n",
            "Epoch 54: val_loss=1.2149\n",
            "Epoch 55: val_loss=1.2214\n",
            "Epoch 56: val_loss=1.3489\n",
            "Epoch 57: val_loss=1.2827\n",
            "Epoch 58: val_loss=1.3861\n",
            "Epoch 59: val_loss=1.2674\n",
            "Epoch 60: val_loss=1.2882\n",
            "Epoch 61: val_loss=1.1909\n",
            "Epoch 62: val_loss=1.3341\n",
            "Epoch 63: val_loss=1.1698\n",
            "Epoch 64: val_loss=1.1860\n",
            "Epoch 65: val_loss=1.2940\n",
            "Epoch 66: val_loss=1.1245\n",
            "Epoch 67: val_loss=1.2282\n",
            "Epoch 68: val_loss=1.1809\n",
            "Epoch 69: val_loss=1.2960\n",
            "Epoch 70: val_loss=1.1674\n",
            "Epoch 71: val_loss=1.2443\n",
            "Epoch 72: val_loss=1.3392\n",
            "Epoch 73: val_loss=1.1200\n",
            "Epoch 74: val_loss=1.0686\n",
            "Epoch 75: val_loss=1.1316\n",
            "Epoch 76: val_loss=1.0768\n",
            "Epoch 77: val_loss=1.1599\n",
            "Epoch 78: val_loss=1.1064\n",
            "Epoch 79: val_loss=1.1079\n",
            "Epoch 80: val_loss=1.1748\n",
            "Epoch 81: val_loss=1.3145\n",
            "Epoch 82: val_loss=1.1342\n",
            "Epoch 83: val_loss=1.2967\n",
            "Epoch 84: val_loss=1.0720\n",
            "Early stopping triggered.\n",
            "MAE : 0.6940, RMSE: 1.0358, R²: 0.2820\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.7771 ± 0.0747\n",
            "RMSE: 1.3122 ± 0.4366\n",
            "R²  : -0.2179 ± 0.8930\n",
            "\n",
            "=== Финальное обучение на всём train+val ===\n",
            "Final model saved to final_mlp_model.pth\n",
            "\n",
            "=== Загрузка модели из файла и тестирование ===\n",
            "Test MAE : 0.6408\n",
            "Test RMSE: 0.8717\n",
            "Test R²  : 0.4819\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "df = pd.read_csv('/content/Mordred_nonagg_pca_processed.csv')\n",
        "X = df.drop(columns=['pIC50']).values.astype(np.float32)\n",
        "y = df['pIC50'].values.astype(np.float32)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=10, max_epochs=100):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            # если нет валидации, просто сохраняем последнюю модель\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32, shuffle=False)\n",
        "\n",
        "        model = MLP(input_dim=X_train.shape[1]).to(device)\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "print(\"\\n=== Финальное обучение на всём train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# сохраняем финальную модель\n",
        "model_path = 'final_mlp_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# загрузка модели из файла и тест\n",
        "print(\"\\n=== Загрузка модели из файла и тестирование ===\")\n",
        "loaded_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обоснование выбора признаков, модели и параметров\n",
        "\n",
        "В качестве признаков использованы дескрипторы Mordred.\n",
        "\n",
        "Для предсказания pIC50 выбрана модель глубокой нейросети (MLP) с тремя скрытыми слоями размерностью 256, 128 и 64 нейрона. Используются LeakyReLU-активации, которые помогают избежать затухающего градиента, и Dropout (0.3) для регуляризации и борьбы с переобучением.\n",
        "\n",
        "Обучение проводится с ранней остановкой (patience = 15, max_epochs = 200) и оптимизатором Adam с пониженным шагом обучения (lr=0.0005) — это позволяет модели сходиться стабильнее и не перепрыгивать минимум.\n",
        "\n",
        "Для оценки используется 5-кратная кросс-валидация. После подбора и обучения модель переобучается на всех обучающих данных и тестируется на отложенной выборке."
      ],
      "metadata": {
        "id": "mmJ3BQlWQOGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=15, max_epochs=200):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=64, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=64, shuffle=False)\n",
        "\n",
        "        model = MLP(input_dim=X_train.shape[1]).to(device)\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "print(\"\\n=== Финальное обучение на всём train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# сохраняем финальную модель\n",
        "model_path = 'final_mlp_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# загрузка модели из файла и тест\n",
        "print(\"\\n=== Загрузка модели из файла и тестирование ===\")\n",
        "loaded_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB5uX0pUBUQX",
        "outputId": "19e22b32-1c6c-43a6-940f-3de74f0c8af5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=6.2429\n",
            "Epoch 2: val_loss=4.0710\n",
            "Epoch 3: val_loss=3.0160\n",
            "Epoch 4: val_loss=2.7243\n",
            "Epoch 5: val_loss=2.5666\n",
            "Epoch 6: val_loss=2.4386\n",
            "Epoch 7: val_loss=2.3777\n",
            "Epoch 8: val_loss=2.3001\n",
            "Epoch 9: val_loss=2.3259\n",
            "Epoch 10: val_loss=2.2793\n",
            "Epoch 11: val_loss=2.2531\n",
            "Epoch 12: val_loss=2.2145\n",
            "Epoch 13: val_loss=2.1238\n",
            "Epoch 14: val_loss=2.1562\n",
            "Epoch 15: val_loss=2.1207\n",
            "Epoch 16: val_loss=2.0943\n",
            "Epoch 17: val_loss=2.0447\n",
            "Epoch 18: val_loss=2.0842\n",
            "Epoch 19: val_loss=2.0257\n",
            "Epoch 20: val_loss=1.9722\n",
            "Epoch 21: val_loss=2.0247\n",
            "Epoch 22: val_loss=1.9841\n",
            "Epoch 23: val_loss=1.8994\n",
            "Epoch 24: val_loss=1.9525\n",
            "Epoch 25: val_loss=1.9193\n",
            "Epoch 26: val_loss=1.9439\n",
            "Epoch 27: val_loss=1.8228\n",
            "Epoch 28: val_loss=1.7876\n",
            "Epoch 29: val_loss=1.8049\n",
            "Epoch 30: val_loss=1.8979\n",
            "Epoch 31: val_loss=1.8015\n",
            "Epoch 32: val_loss=1.7978\n",
            "Epoch 33: val_loss=1.8398\n",
            "Epoch 34: val_loss=1.6870\n",
            "Epoch 35: val_loss=1.6704\n",
            "Epoch 36: val_loss=1.6651\n",
            "Epoch 37: val_loss=1.7259\n",
            "Epoch 38: val_loss=1.5961\n",
            "Epoch 39: val_loss=1.6640\n",
            "Epoch 40: val_loss=1.5770\n",
            "Epoch 41: val_loss=1.5354\n",
            "Epoch 42: val_loss=1.5585\n",
            "Epoch 43: val_loss=1.6208\n",
            "Epoch 44: val_loss=1.5338\n",
            "Epoch 45: val_loss=1.5158\n",
            "Epoch 46: val_loss=1.4876\n",
            "Epoch 47: val_loss=1.5096\n",
            "Epoch 48: val_loss=1.5100\n",
            "Epoch 49: val_loss=1.6127\n",
            "Epoch 50: val_loss=1.4905\n",
            "Epoch 51: val_loss=1.4902\n",
            "Epoch 52: val_loss=1.4411\n",
            "Epoch 53: val_loss=1.4812\n",
            "Epoch 54: val_loss=1.4357\n",
            "Epoch 55: val_loss=1.4269\n",
            "Epoch 56: val_loss=1.4932\n",
            "Epoch 57: val_loss=1.4087\n",
            "Epoch 58: val_loss=1.4200\n",
            "Epoch 59: val_loss=1.4544\n",
            "Epoch 60: val_loss=1.4744\n",
            "Epoch 61: val_loss=1.4516\n",
            "Epoch 62: val_loss=1.3755\n",
            "Epoch 63: val_loss=1.4022\n",
            "Epoch 64: val_loss=1.3656\n",
            "Epoch 65: val_loss=1.4233\n",
            "Epoch 66: val_loss=1.3350\n",
            "Epoch 67: val_loss=1.4504\n",
            "Epoch 68: val_loss=1.3505\n",
            "Epoch 69: val_loss=1.3557\n",
            "Epoch 70: val_loss=1.3512\n",
            "Epoch 71: val_loss=1.3525\n",
            "Epoch 72: val_loss=1.3431\n",
            "Epoch 73: val_loss=1.3195\n",
            "Epoch 74: val_loss=1.3288\n",
            "Epoch 75: val_loss=1.3070\n",
            "Epoch 76: val_loss=1.2645\n",
            "Epoch 77: val_loss=1.3110\n",
            "Epoch 78: val_loss=1.3689\n",
            "Epoch 79: val_loss=1.3025\n",
            "Epoch 80: val_loss=1.3250\n",
            "Epoch 81: val_loss=1.2719\n",
            "Epoch 82: val_loss=1.3468\n",
            "Epoch 83: val_loss=1.2863\n",
            "Epoch 84: val_loss=1.2744\n",
            "Epoch 85: val_loss=1.2946\n",
            "Epoch 86: val_loss=1.3130\n",
            "Epoch 87: val_loss=1.2586\n",
            "Epoch 88: val_loss=1.2466\n",
            "Epoch 89: val_loss=1.2223\n",
            "Epoch 90: val_loss=1.2447\n",
            "Epoch 91: val_loss=1.2598\n",
            "Epoch 92: val_loss=1.2192\n",
            "Epoch 93: val_loss=1.2616\n",
            "Epoch 94: val_loss=1.2344\n",
            "Epoch 95: val_loss=1.2376\n",
            "Epoch 96: val_loss=1.1708\n",
            "Epoch 97: val_loss=1.2204\n",
            "Epoch 98: val_loss=1.2393\n",
            "Epoch 99: val_loss=1.2084\n",
            "Epoch 100: val_loss=1.2148\n",
            "Epoch 101: val_loss=1.2387\n",
            "Epoch 102: val_loss=1.1393\n",
            "Epoch 103: val_loss=1.1914\n",
            "Epoch 104: val_loss=1.1918\n",
            "Epoch 105: val_loss=1.1881\n",
            "Epoch 106: val_loss=1.1582\n",
            "Epoch 107: val_loss=1.1751\n",
            "Epoch 108: val_loss=1.1550\n",
            "Epoch 109: val_loss=1.1057\n",
            "Epoch 110: val_loss=1.1081\n",
            "Epoch 111: val_loss=1.1564\n",
            "Epoch 112: val_loss=1.1260\n",
            "Epoch 113: val_loss=1.1554\n",
            "Epoch 114: val_loss=1.1007\n",
            "Epoch 115: val_loss=1.1816\n",
            "Epoch 116: val_loss=1.1096\n",
            "Epoch 117: val_loss=1.2739\n",
            "Epoch 118: val_loss=1.0621\n",
            "Epoch 119: val_loss=1.1402\n",
            "Epoch 120: val_loss=1.1017\n",
            "Epoch 121: val_loss=1.1141\n",
            "Epoch 122: val_loss=1.1497\n",
            "Epoch 123: val_loss=1.0826\n",
            "Epoch 124: val_loss=1.0918\n",
            "Epoch 125: val_loss=1.0853\n",
            "Epoch 126: val_loss=1.0976\n",
            "Epoch 127: val_loss=1.0763\n",
            "Epoch 128: val_loss=1.0800\n",
            "Epoch 129: val_loss=1.1600\n",
            "Epoch 130: val_loss=1.1693\n",
            "Epoch 131: val_loss=1.1531\n",
            "Epoch 132: val_loss=1.1510\n",
            "Epoch 133: val_loss=1.1500\n",
            "Early stopping triggered.\n",
            "MAE : 0.6681, RMSE: 1.0790, R²: 0.2170\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=6.9251\n",
            "Epoch 2: val_loss=3.5563\n",
            "Epoch 3: val_loss=2.4973\n",
            "Epoch 4: val_loss=2.1113\n",
            "Epoch 5: val_loss=1.9739\n",
            "Epoch 6: val_loss=1.8660\n",
            "Epoch 7: val_loss=1.7870\n",
            "Epoch 8: val_loss=1.7223\n",
            "Epoch 9: val_loss=1.6438\n",
            "Epoch 10: val_loss=1.6562\n",
            "Epoch 11: val_loss=1.6040\n",
            "Epoch 12: val_loss=1.5930\n",
            "Epoch 13: val_loss=1.5660\n",
            "Epoch 14: val_loss=1.5185\n",
            "Epoch 15: val_loss=1.4957\n",
            "Epoch 16: val_loss=1.4481\n",
            "Epoch 17: val_loss=1.4297\n",
            "Epoch 18: val_loss=1.3945\n",
            "Epoch 19: val_loss=1.4041\n",
            "Epoch 20: val_loss=1.3652\n",
            "Epoch 21: val_loss=1.3477\n",
            "Epoch 22: val_loss=1.3281\n",
            "Epoch 23: val_loss=1.3291\n",
            "Epoch 24: val_loss=1.3366\n",
            "Epoch 25: val_loss=1.3188\n",
            "Epoch 26: val_loss=1.2889\n",
            "Epoch 27: val_loss=1.2627\n",
            "Epoch 28: val_loss=1.2454\n",
            "Epoch 29: val_loss=1.2501\n",
            "Epoch 30: val_loss=1.2830\n",
            "Epoch 31: val_loss=1.2134\n",
            "Epoch 32: val_loss=1.2115\n",
            "Epoch 33: val_loss=1.2082\n",
            "Epoch 34: val_loss=1.2220\n",
            "Epoch 35: val_loss=1.2104\n",
            "Epoch 36: val_loss=1.1794\n",
            "Epoch 37: val_loss=1.1718\n",
            "Epoch 38: val_loss=1.1771\n",
            "Epoch 39: val_loss=1.1976\n",
            "Epoch 40: val_loss=1.1784\n",
            "Epoch 41: val_loss=1.1593\n",
            "Epoch 42: val_loss=1.1858\n",
            "Epoch 43: val_loss=1.1599\n",
            "Epoch 44: val_loss=1.1806\n",
            "Epoch 45: val_loss=1.1428\n",
            "Epoch 46: val_loss=1.1392\n",
            "Epoch 47: val_loss=1.1346\n",
            "Epoch 48: val_loss=1.1204\n",
            "Epoch 49: val_loss=1.1505\n",
            "Epoch 50: val_loss=1.1928\n",
            "Epoch 51: val_loss=1.1188\n",
            "Epoch 52: val_loss=1.1004\n",
            "Epoch 53: val_loss=1.1075\n",
            "Epoch 54: val_loss=1.1022\n",
            "Epoch 55: val_loss=1.0964\n",
            "Epoch 56: val_loss=1.1093\n",
            "Epoch 57: val_loss=1.0929\n",
            "Epoch 58: val_loss=1.1209\n",
            "Epoch 59: val_loss=1.1202\n",
            "Epoch 60: val_loss=1.0832\n",
            "Epoch 61: val_loss=1.0863\n",
            "Epoch 62: val_loss=1.0634\n",
            "Epoch 63: val_loss=1.0785\n",
            "Epoch 64: val_loss=1.0461\n",
            "Epoch 65: val_loss=1.0604\n",
            "Epoch 66: val_loss=1.0886\n",
            "Epoch 67: val_loss=1.0602\n",
            "Epoch 68: val_loss=1.0765\n",
            "Epoch 69: val_loss=1.0744\n",
            "Epoch 70: val_loss=1.0512\n",
            "Epoch 71: val_loss=1.0727\n",
            "Epoch 72: val_loss=1.0842\n",
            "Epoch 73: val_loss=1.0931\n",
            "Epoch 74: val_loss=1.0693\n",
            "Epoch 75: val_loss=1.0286\n",
            "Epoch 76: val_loss=1.0618\n",
            "Epoch 77: val_loss=1.0278\n",
            "Epoch 78: val_loss=1.0414\n",
            "Epoch 79: val_loss=1.0454\n",
            "Epoch 80: val_loss=1.0538\n",
            "Epoch 81: val_loss=1.0211\n",
            "Epoch 82: val_loss=1.0243\n",
            "Epoch 83: val_loss=1.0101\n",
            "Epoch 84: val_loss=1.0255\n",
            "Epoch 85: val_loss=1.0448\n",
            "Epoch 86: val_loss=1.0098\n",
            "Epoch 87: val_loss=0.9978\n",
            "Epoch 88: val_loss=1.0158\n",
            "Epoch 89: val_loss=1.0231\n",
            "Epoch 90: val_loss=0.9894\n",
            "Epoch 91: val_loss=1.0808\n",
            "Epoch 92: val_loss=1.0005\n",
            "Epoch 93: val_loss=1.0192\n",
            "Epoch 94: val_loss=1.0119\n",
            "Epoch 95: val_loss=0.9884\n",
            "Epoch 96: val_loss=1.0147\n",
            "Epoch 97: val_loss=0.9848\n",
            "Epoch 98: val_loss=1.0051\n",
            "Epoch 99: val_loss=0.9824\n",
            "Epoch 100: val_loss=0.9892\n",
            "Epoch 101: val_loss=0.9811\n",
            "Epoch 102: val_loss=1.0039\n",
            "Epoch 103: val_loss=0.9759\n",
            "Epoch 104: val_loss=0.9593\n",
            "Epoch 105: val_loss=0.9655\n",
            "Epoch 106: val_loss=0.9726\n",
            "Epoch 107: val_loss=0.9656\n",
            "Epoch 108: val_loss=0.9777\n",
            "Epoch 109: val_loss=0.9861\n",
            "Epoch 110: val_loss=0.9525\n",
            "Epoch 111: val_loss=0.9366\n",
            "Epoch 112: val_loss=0.9416\n",
            "Epoch 113: val_loss=0.9519\n",
            "Epoch 114: val_loss=0.9661\n",
            "Epoch 115: val_loss=0.9458\n",
            "Epoch 116: val_loss=0.9448\n",
            "Epoch 117: val_loss=0.9492\n",
            "Epoch 118: val_loss=0.9641\n",
            "Epoch 119: val_loss=0.9805\n",
            "Epoch 120: val_loss=0.9658\n",
            "Epoch 121: val_loss=0.9524\n",
            "Epoch 122: val_loss=0.9583\n",
            "Epoch 123: val_loss=0.9586\n",
            "Epoch 124: val_loss=0.9929\n",
            "Epoch 125: val_loss=0.9618\n",
            "Epoch 126: val_loss=0.9478\n",
            "Early stopping triggered.\n",
            "MAE : 0.7345, RMSE: 0.9794, R²: 0.4154\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=8.5006\n",
            "Epoch 2: val_loss=4.7830\n",
            "Epoch 3: val_loss=3.7102\n",
            "Epoch 4: val_loss=3.1425\n",
            "Epoch 5: val_loss=2.8294\n",
            "Epoch 6: val_loss=2.7380\n",
            "Epoch 7: val_loss=2.5882\n",
            "Epoch 8: val_loss=2.5237\n",
            "Epoch 9: val_loss=2.5170\n",
            "Epoch 10: val_loss=2.3804\n",
            "Epoch 11: val_loss=2.3485\n",
            "Epoch 12: val_loss=2.2897\n",
            "Epoch 13: val_loss=2.3080\n",
            "Epoch 14: val_loss=2.1815\n",
            "Epoch 15: val_loss=2.1398\n",
            "Epoch 16: val_loss=2.1219\n",
            "Epoch 17: val_loss=2.0866\n",
            "Epoch 18: val_loss=2.0753\n",
            "Epoch 19: val_loss=2.0456\n",
            "Epoch 20: val_loss=2.0023\n",
            "Epoch 21: val_loss=2.0039\n",
            "Epoch 22: val_loss=1.9822\n",
            "Epoch 23: val_loss=2.0835\n",
            "Epoch 24: val_loss=1.9791\n",
            "Epoch 25: val_loss=1.9786\n",
            "Epoch 26: val_loss=1.8524\n",
            "Epoch 27: val_loss=1.9551\n",
            "Epoch 28: val_loss=1.7763\n",
            "Epoch 29: val_loss=1.8068\n",
            "Epoch 30: val_loss=1.7960\n",
            "Epoch 31: val_loss=1.7621\n",
            "Epoch 32: val_loss=1.7374\n",
            "Epoch 33: val_loss=1.6994\n",
            "Epoch 34: val_loss=1.7347\n",
            "Epoch 35: val_loss=1.6708\n",
            "Epoch 36: val_loss=1.6671\n",
            "Epoch 37: val_loss=1.5926\n",
            "Epoch 38: val_loss=1.6811\n",
            "Epoch 39: val_loss=1.5097\n",
            "Epoch 40: val_loss=1.5548\n",
            "Epoch 41: val_loss=1.5666\n",
            "Epoch 42: val_loss=1.5663\n",
            "Epoch 43: val_loss=1.5444\n",
            "Epoch 44: val_loss=1.6049\n",
            "Epoch 45: val_loss=1.4849\n",
            "Epoch 46: val_loss=1.4834\n",
            "Epoch 47: val_loss=1.4688\n",
            "Epoch 48: val_loss=1.4145\n",
            "Epoch 49: val_loss=1.4606\n",
            "Epoch 50: val_loss=1.4290\n",
            "Epoch 51: val_loss=1.4049\n",
            "Epoch 52: val_loss=1.3952\n",
            "Epoch 53: val_loss=1.4212\n",
            "Epoch 54: val_loss=1.4913\n",
            "Epoch 55: val_loss=1.4374\n",
            "Epoch 56: val_loss=1.4426\n",
            "Epoch 57: val_loss=1.4232\n",
            "Epoch 58: val_loss=1.3743\n",
            "Epoch 59: val_loss=1.3829\n",
            "Epoch 60: val_loss=1.3521\n",
            "Epoch 61: val_loss=1.4100\n",
            "Epoch 62: val_loss=1.4047\n",
            "Epoch 63: val_loss=1.3687\n",
            "Epoch 64: val_loss=1.4243\n",
            "Epoch 65: val_loss=1.3500\n",
            "Epoch 66: val_loss=1.3408\n",
            "Epoch 67: val_loss=1.3211\n",
            "Epoch 68: val_loss=1.3221\n",
            "Epoch 69: val_loss=1.3554\n",
            "Epoch 70: val_loss=1.2976\n",
            "Epoch 71: val_loss=1.2942\n",
            "Epoch 72: val_loss=1.2903\n",
            "Epoch 73: val_loss=1.2945\n",
            "Epoch 74: val_loss=1.2969\n",
            "Epoch 75: val_loss=1.3055\n",
            "Epoch 76: val_loss=1.2379\n",
            "Epoch 77: val_loss=1.3140\n",
            "Epoch 78: val_loss=1.3064\n",
            "Epoch 79: val_loss=1.2882\n",
            "Epoch 80: val_loss=1.2757\n",
            "Epoch 81: val_loss=1.3258\n",
            "Epoch 82: val_loss=1.2950\n",
            "Epoch 83: val_loss=1.2760\n",
            "Epoch 84: val_loss=1.2742\n",
            "Epoch 85: val_loss=1.3053\n",
            "Epoch 86: val_loss=1.2448\n",
            "Epoch 87: val_loss=1.2341\n",
            "Epoch 88: val_loss=1.2162\n",
            "Epoch 89: val_loss=1.2406\n",
            "Epoch 90: val_loss=1.2134\n",
            "Epoch 91: val_loss=1.2481\n",
            "Epoch 92: val_loss=1.2279\n",
            "Epoch 93: val_loss=1.2126\n",
            "Epoch 94: val_loss=1.2429\n",
            "Epoch 95: val_loss=1.1875\n",
            "Epoch 96: val_loss=1.1970\n",
            "Epoch 97: val_loss=1.2402\n",
            "Epoch 98: val_loss=1.1903\n",
            "Epoch 99: val_loss=1.1853\n",
            "Epoch 100: val_loss=1.1550\n",
            "Epoch 101: val_loss=1.1613\n",
            "Epoch 102: val_loss=1.1669\n",
            "Epoch 103: val_loss=1.1172\n",
            "Epoch 104: val_loss=1.1094\n",
            "Epoch 105: val_loss=1.1149\n",
            "Epoch 106: val_loss=1.0903\n",
            "Epoch 107: val_loss=1.0952\n",
            "Epoch 108: val_loss=1.0912\n",
            "Epoch 109: val_loss=1.1212\n",
            "Epoch 110: val_loss=1.1074\n",
            "Epoch 111: val_loss=1.0846\n",
            "Epoch 112: val_loss=1.0922\n",
            "Epoch 113: val_loss=1.0854\n",
            "Epoch 114: val_loss=1.0659\n",
            "Epoch 115: val_loss=1.0782\n",
            "Epoch 116: val_loss=1.0856\n",
            "Epoch 117: val_loss=1.0808\n",
            "Epoch 118: val_loss=1.1036\n",
            "Epoch 119: val_loss=1.1303\n",
            "Epoch 120: val_loss=1.1045\n",
            "Epoch 121: val_loss=1.0577\n",
            "Epoch 122: val_loss=1.0735\n",
            "Epoch 123: val_loss=1.0744\n",
            "Epoch 124: val_loss=1.1105\n",
            "Epoch 125: val_loss=1.0253\n",
            "Epoch 126: val_loss=1.0529\n",
            "Epoch 127: val_loss=1.0164\n",
            "Epoch 128: val_loss=1.0321\n",
            "Epoch 129: val_loss=1.0343\n",
            "Epoch 130: val_loss=1.0383\n",
            "Epoch 131: val_loss=1.0211\n",
            "Epoch 132: val_loss=1.0238\n",
            "Epoch 133: val_loss=1.0645\n",
            "Epoch 134: val_loss=1.0171\n",
            "Epoch 135: val_loss=1.0416\n",
            "Epoch 136: val_loss=1.0099\n",
            "Epoch 137: val_loss=1.0422\n",
            "Epoch 138: val_loss=0.9991\n",
            "Epoch 139: val_loss=1.0182\n",
            "Epoch 140: val_loss=1.0195\n",
            "Epoch 141: val_loss=1.0128\n",
            "Epoch 142: val_loss=1.0332\n",
            "Epoch 143: val_loss=1.0147\n",
            "Epoch 144: val_loss=1.0151\n",
            "Epoch 145: val_loss=0.9945\n",
            "Epoch 146: val_loss=0.9981\n",
            "Epoch 147: val_loss=1.0088\n",
            "Epoch 148: val_loss=1.0347\n",
            "Epoch 149: val_loss=1.0227\n",
            "Epoch 150: val_loss=0.9883\n",
            "Epoch 151: val_loss=0.9993\n",
            "Epoch 152: val_loss=0.9932\n",
            "Epoch 153: val_loss=1.0046\n",
            "Epoch 154: val_loss=0.9849\n",
            "Epoch 155: val_loss=0.9953\n",
            "Epoch 156: val_loss=0.9885\n",
            "Epoch 157: val_loss=1.0057\n",
            "Epoch 158: val_loss=1.0379\n",
            "Epoch 159: val_loss=0.9726\n",
            "Epoch 160: val_loss=0.9854\n",
            "Epoch 161: val_loss=1.0023\n",
            "Epoch 162: val_loss=1.0093\n",
            "Epoch 163: val_loss=0.9925\n",
            "Epoch 164: val_loss=0.9898\n",
            "Epoch 165: val_loss=0.9788\n",
            "Epoch 166: val_loss=0.9648\n",
            "Epoch 167: val_loss=1.0023\n",
            "Epoch 168: val_loss=0.9639\n",
            "Epoch 169: val_loss=0.9646\n",
            "Epoch 170: val_loss=0.9930\n",
            "Epoch 171: val_loss=0.9649\n",
            "Epoch 172: val_loss=0.9843\n",
            "Epoch 173: val_loss=0.9881\n",
            "Epoch 174: val_loss=1.0049\n",
            "Epoch 175: val_loss=0.9887\n",
            "Epoch 176: val_loss=0.9692\n",
            "Epoch 177: val_loss=0.9986\n",
            "Epoch 178: val_loss=0.9776\n",
            "Epoch 179: val_loss=1.0215\n",
            "Epoch 180: val_loss=0.9709\n",
            "Epoch 181: val_loss=1.0167\n",
            "Epoch 182: val_loss=0.9707\n",
            "Epoch 183: val_loss=0.9665\n",
            "Early stopping triggered.\n",
            "MAE : 0.6717, RMSE: 0.9872, R²: 0.3957\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=14.6716\n",
            "Epoch 2: val_loss=9.5289\n",
            "Epoch 3: val_loss=8.1486\n",
            "Epoch 4: val_loss=7.3223\n",
            "Epoch 5: val_loss=6.7715\n",
            "Epoch 6: val_loss=6.4368\n",
            "Epoch 7: val_loss=6.5215\n",
            "Epoch 8: val_loss=6.1625\n",
            "Epoch 9: val_loss=6.0415\n",
            "Epoch 10: val_loss=5.7779\n",
            "Epoch 11: val_loss=5.6662\n",
            "Epoch 12: val_loss=5.6897\n",
            "Epoch 13: val_loss=5.4423\n",
            "Epoch 14: val_loss=5.5160\n",
            "Epoch 15: val_loss=5.4930\n",
            "Epoch 16: val_loss=5.3388\n",
            "Epoch 17: val_loss=5.1132\n",
            "Epoch 18: val_loss=4.9734\n",
            "Epoch 19: val_loss=4.9785\n",
            "Epoch 20: val_loss=4.9099\n",
            "Epoch 21: val_loss=5.0448\n",
            "Epoch 22: val_loss=5.0873\n",
            "Epoch 23: val_loss=4.9833\n",
            "Epoch 24: val_loss=5.0948\n",
            "Epoch 25: val_loss=4.9799\n",
            "Epoch 26: val_loss=4.7540\n",
            "Epoch 27: val_loss=4.6613\n",
            "Epoch 28: val_loss=4.8779\n",
            "Epoch 29: val_loss=4.8447\n",
            "Epoch 30: val_loss=4.7408\n",
            "Epoch 31: val_loss=4.6536\n",
            "Epoch 32: val_loss=4.4096\n",
            "Epoch 33: val_loss=4.4902\n",
            "Epoch 34: val_loss=4.5126\n",
            "Epoch 35: val_loss=4.3850\n",
            "Epoch 36: val_loss=4.3014\n",
            "Epoch 37: val_loss=4.2630\n",
            "Epoch 38: val_loss=4.0283\n",
            "Epoch 39: val_loss=4.1685\n",
            "Epoch 40: val_loss=4.3497\n",
            "Epoch 41: val_loss=4.4451\n",
            "Epoch 42: val_loss=4.2234\n",
            "Epoch 43: val_loss=4.4134\n",
            "Epoch 44: val_loss=4.1002\n",
            "Epoch 45: val_loss=4.1665\n",
            "Epoch 46: val_loss=4.2239\n",
            "Epoch 47: val_loss=4.1602\n",
            "Epoch 48: val_loss=3.9675\n",
            "Epoch 49: val_loss=4.0868\n",
            "Epoch 50: val_loss=4.0424\n",
            "Epoch 51: val_loss=4.0201\n",
            "Epoch 52: val_loss=4.0025\n",
            "Epoch 53: val_loss=3.8236\n",
            "Epoch 54: val_loss=4.0335\n",
            "Epoch 55: val_loss=3.7304\n",
            "Epoch 56: val_loss=3.8359\n",
            "Epoch 57: val_loss=3.8258\n",
            "Epoch 58: val_loss=3.6539\n",
            "Epoch 59: val_loss=3.6523\n",
            "Epoch 60: val_loss=3.4196\n",
            "Epoch 61: val_loss=3.5097\n",
            "Epoch 62: val_loss=3.5771\n",
            "Epoch 63: val_loss=3.3663\n",
            "Epoch 64: val_loss=3.2686\n",
            "Epoch 65: val_loss=3.4105\n",
            "Epoch 66: val_loss=3.4042\n",
            "Epoch 67: val_loss=3.4642\n",
            "Epoch 68: val_loss=3.4092\n",
            "Epoch 69: val_loss=3.4627\n",
            "Epoch 70: val_loss=3.3099\n",
            "Epoch 71: val_loss=3.4005\n",
            "Epoch 72: val_loss=3.2780\n",
            "Epoch 73: val_loss=3.4020\n",
            "Epoch 74: val_loss=3.2539\n",
            "Epoch 75: val_loss=3.3923\n",
            "Epoch 76: val_loss=3.4148\n",
            "Epoch 77: val_loss=3.1334\n",
            "Epoch 78: val_loss=3.2203\n",
            "Epoch 79: val_loss=3.3220\n",
            "Epoch 80: val_loss=3.3766\n",
            "Epoch 81: val_loss=3.2269\n",
            "Epoch 82: val_loss=3.1320\n",
            "Epoch 83: val_loss=3.0920\n",
            "Epoch 84: val_loss=3.0751\n",
            "Epoch 85: val_loss=3.0121\n",
            "Epoch 86: val_loss=3.1811\n",
            "Epoch 87: val_loss=3.0728\n",
            "Epoch 88: val_loss=3.1758\n",
            "Epoch 89: val_loss=3.0674\n",
            "Epoch 90: val_loss=2.9023\n",
            "Epoch 91: val_loss=3.2089\n",
            "Epoch 92: val_loss=3.0071\n",
            "Epoch 93: val_loss=2.8459\n",
            "Epoch 94: val_loss=2.9129\n",
            "Epoch 95: val_loss=2.8822\n",
            "Epoch 96: val_loss=2.7537\n",
            "Epoch 97: val_loss=2.9763\n",
            "Epoch 98: val_loss=2.8431\n",
            "Epoch 99: val_loss=2.9247\n",
            "Epoch 100: val_loss=2.8114\n",
            "Epoch 101: val_loss=2.6735\n",
            "Epoch 102: val_loss=2.5942\n",
            "Epoch 103: val_loss=2.7933\n",
            "Epoch 104: val_loss=2.9724\n",
            "Epoch 105: val_loss=2.6527\n",
            "Epoch 106: val_loss=2.9930\n",
            "Epoch 107: val_loss=2.8890\n",
            "Epoch 108: val_loss=2.8321\n",
            "Epoch 109: val_loss=2.9065\n",
            "Epoch 110: val_loss=2.6575\n",
            "Epoch 111: val_loss=2.9204\n",
            "Epoch 112: val_loss=2.7682\n",
            "Epoch 113: val_loss=2.8841\n",
            "Epoch 114: val_loss=2.8196\n",
            "Epoch 115: val_loss=3.0248\n",
            "Epoch 116: val_loss=2.7561\n",
            "Epoch 117: val_loss=2.5162\n",
            "Epoch 118: val_loss=2.6883\n",
            "Epoch 119: val_loss=2.6770\n",
            "Epoch 120: val_loss=2.6254\n",
            "Epoch 121: val_loss=2.6009\n",
            "Epoch 122: val_loss=2.6272\n",
            "Epoch 123: val_loss=2.4939\n",
            "Epoch 124: val_loss=2.5397\n",
            "Epoch 125: val_loss=2.5181\n",
            "Epoch 126: val_loss=2.4845\n",
            "Epoch 127: val_loss=2.5562\n",
            "Epoch 128: val_loss=2.5633\n",
            "Epoch 129: val_loss=2.4608\n",
            "Epoch 130: val_loss=2.4625\n",
            "Epoch 131: val_loss=2.4699\n",
            "Epoch 132: val_loss=2.5540\n",
            "Epoch 133: val_loss=2.4295\n",
            "Epoch 134: val_loss=2.5565\n",
            "Epoch 135: val_loss=2.5922\n",
            "Epoch 136: val_loss=2.4987\n",
            "Epoch 137: val_loss=2.5239\n",
            "Epoch 138: val_loss=2.4859\n",
            "Epoch 139: val_loss=2.3404\n",
            "Epoch 140: val_loss=2.3711\n",
            "Epoch 141: val_loss=2.3059\n",
            "Epoch 142: val_loss=2.4388\n",
            "Epoch 143: val_loss=2.7837\n",
            "Epoch 144: val_loss=2.3200\n",
            "Epoch 145: val_loss=2.4058\n",
            "Epoch 146: val_loss=2.5416\n",
            "Epoch 147: val_loss=2.5543\n",
            "Epoch 148: val_loss=2.5480\n",
            "Epoch 149: val_loss=2.6014\n",
            "Epoch 150: val_loss=2.7885\n",
            "Epoch 151: val_loss=2.4888\n",
            "Epoch 152: val_loss=2.5189\n",
            "Epoch 153: val_loss=2.5956\n",
            "Epoch 154: val_loss=2.4800\n",
            "Epoch 155: val_loss=2.4722\n",
            "Epoch 156: val_loss=2.5722\n",
            "Early stopping triggered.\n",
            "MAE : 0.7793, RMSE: 1.6348, R²: -0.6882\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=7.7032\n",
            "Epoch 2: val_loss=4.8082\n",
            "Epoch 3: val_loss=3.6140\n",
            "Epoch 4: val_loss=3.2417\n",
            "Epoch 5: val_loss=2.8187\n",
            "Epoch 6: val_loss=2.6649\n",
            "Epoch 7: val_loss=2.5322\n",
            "Epoch 8: val_loss=2.4534\n",
            "Epoch 9: val_loss=2.3719\n",
            "Epoch 10: val_loss=2.3015\n",
            "Epoch 11: val_loss=2.2451\n",
            "Epoch 12: val_loss=2.1813\n",
            "Epoch 13: val_loss=2.1217\n",
            "Epoch 14: val_loss=2.0767\n",
            "Epoch 15: val_loss=2.0736\n",
            "Epoch 16: val_loss=2.0323\n",
            "Epoch 17: val_loss=2.0306\n",
            "Epoch 18: val_loss=1.9923\n",
            "Epoch 19: val_loss=2.0263\n",
            "Epoch 20: val_loss=1.9810\n",
            "Epoch 21: val_loss=1.9023\n",
            "Epoch 22: val_loss=1.9015\n",
            "Epoch 23: val_loss=1.8898\n",
            "Epoch 24: val_loss=1.8384\n",
            "Epoch 25: val_loss=1.8069\n",
            "Epoch 26: val_loss=1.7933\n",
            "Epoch 27: val_loss=1.8324\n",
            "Epoch 28: val_loss=1.7175\n",
            "Epoch 29: val_loss=1.7081\n",
            "Epoch 30: val_loss=1.7112\n",
            "Epoch 31: val_loss=1.6857\n",
            "Epoch 32: val_loss=1.6012\n",
            "Epoch 33: val_loss=1.5849\n",
            "Epoch 34: val_loss=1.5559\n",
            "Epoch 35: val_loss=1.5660\n",
            "Epoch 36: val_loss=1.5573\n",
            "Epoch 37: val_loss=1.5451\n",
            "Epoch 38: val_loss=1.4906\n",
            "Epoch 39: val_loss=1.4977\n",
            "Epoch 40: val_loss=1.5017\n",
            "Epoch 41: val_loss=1.4559\n",
            "Epoch 42: val_loss=1.4494\n",
            "Epoch 43: val_loss=1.4285\n",
            "Epoch 44: val_loss=1.4420\n",
            "Epoch 45: val_loss=1.3991\n",
            "Epoch 46: val_loss=1.4086\n",
            "Epoch 47: val_loss=1.3586\n",
            "Epoch 48: val_loss=1.3771\n",
            "Epoch 49: val_loss=1.3744\n",
            "Epoch 50: val_loss=1.4200\n",
            "Epoch 51: val_loss=1.3539\n",
            "Epoch 52: val_loss=1.3657\n",
            "Epoch 53: val_loss=1.3603\n",
            "Epoch 54: val_loss=1.3413\n",
            "Epoch 55: val_loss=1.3266\n",
            "Epoch 56: val_loss=1.3344\n",
            "Epoch 57: val_loss=1.3369\n",
            "Epoch 58: val_loss=1.3253\n",
            "Epoch 59: val_loss=1.3123\n",
            "Epoch 60: val_loss=1.3219\n",
            "Epoch 61: val_loss=1.3052\n",
            "Epoch 62: val_loss=1.2732\n",
            "Epoch 63: val_loss=1.2815\n",
            "Epoch 64: val_loss=1.2471\n",
            "Epoch 65: val_loss=1.2446\n",
            "Epoch 66: val_loss=1.2759\n",
            "Epoch 67: val_loss=1.2324\n",
            "Epoch 68: val_loss=1.2087\n",
            "Epoch 69: val_loss=1.2272\n",
            "Epoch 70: val_loss=1.1796\n",
            "Epoch 71: val_loss=1.1888\n",
            "Epoch 72: val_loss=1.2476\n",
            "Epoch 73: val_loss=1.2131\n",
            "Epoch 74: val_loss=1.2141\n",
            "Epoch 75: val_loss=1.2064\n",
            "Epoch 76: val_loss=1.2117\n",
            "Epoch 77: val_loss=1.1519\n",
            "Epoch 78: val_loss=1.1866\n",
            "Epoch 79: val_loss=1.1745\n",
            "Epoch 80: val_loss=1.1828\n",
            "Epoch 81: val_loss=1.1682\n",
            "Epoch 82: val_loss=1.1557\n",
            "Epoch 83: val_loss=1.2033\n",
            "Epoch 84: val_loss=1.0975\n",
            "Epoch 85: val_loss=1.1037\n",
            "Epoch 86: val_loss=1.1492\n",
            "Epoch 87: val_loss=1.1021\n",
            "Epoch 88: val_loss=1.0753\n",
            "Epoch 89: val_loss=1.1161\n",
            "Epoch 90: val_loss=1.0867\n",
            "Epoch 91: val_loss=1.1304\n",
            "Epoch 92: val_loss=1.1183\n",
            "Epoch 93: val_loss=1.0764\n",
            "Epoch 94: val_loss=1.1088\n",
            "Epoch 95: val_loss=1.1358\n",
            "Epoch 96: val_loss=1.0688\n",
            "Epoch 97: val_loss=1.0272\n",
            "Epoch 98: val_loss=1.0453\n",
            "Epoch 99: val_loss=1.0933\n",
            "Epoch 100: val_loss=1.0510\n",
            "Epoch 101: val_loss=1.0766\n",
            "Epoch 102: val_loss=1.0910\n",
            "Epoch 103: val_loss=1.0817\n",
            "Epoch 104: val_loss=1.0718\n",
            "Epoch 105: val_loss=1.0718\n",
            "Epoch 106: val_loss=1.0922\n",
            "Epoch 107: val_loss=1.0813\n",
            "Epoch 108: val_loss=1.0703\n",
            "Epoch 109: val_loss=1.0427\n",
            "Epoch 110: val_loss=1.0507\n",
            "Epoch 111: val_loss=1.0120\n",
            "Epoch 112: val_loss=1.0046\n",
            "Epoch 113: val_loss=1.0089\n",
            "Epoch 114: val_loss=1.0004\n",
            "Epoch 115: val_loss=1.0196\n",
            "Epoch 116: val_loss=1.0109\n",
            "Epoch 117: val_loss=1.0418\n",
            "Epoch 118: val_loss=1.0192\n",
            "Epoch 119: val_loss=1.0173\n",
            "Epoch 120: val_loss=1.0074\n",
            "Epoch 121: val_loss=1.0177\n",
            "Epoch 122: val_loss=0.9965\n",
            "Epoch 123: val_loss=0.9846\n",
            "Epoch 124: val_loss=0.9946\n",
            "Epoch 125: val_loss=0.9700\n",
            "Epoch 126: val_loss=0.9831\n",
            "Epoch 127: val_loss=0.9850\n",
            "Epoch 128: val_loss=1.0024\n",
            "Epoch 129: val_loss=0.9912\n",
            "Epoch 130: val_loss=1.0026\n",
            "Epoch 131: val_loss=0.9795\n",
            "Epoch 132: val_loss=0.9676\n",
            "Epoch 133: val_loss=0.9719\n",
            "Epoch 134: val_loss=0.9643\n",
            "Epoch 135: val_loss=0.9450\n",
            "Epoch 136: val_loss=0.9906\n",
            "Epoch 137: val_loss=0.9557\n",
            "Epoch 138: val_loss=0.9849\n",
            "Epoch 139: val_loss=0.9352\n",
            "Epoch 140: val_loss=0.9830\n",
            "Epoch 141: val_loss=0.9383\n",
            "Epoch 142: val_loss=0.9279\n",
            "Epoch 143: val_loss=0.9418\n",
            "Epoch 144: val_loss=0.9475\n",
            "Epoch 145: val_loss=0.9376\n",
            "Epoch 146: val_loss=0.9487\n",
            "Epoch 147: val_loss=0.9524\n",
            "Epoch 148: val_loss=0.9692\n",
            "Epoch 149: val_loss=0.9762\n",
            "Epoch 150: val_loss=0.9484\n",
            "Epoch 151: val_loss=0.9388\n",
            "Epoch 152: val_loss=0.9870\n",
            "Epoch 153: val_loss=0.9339\n",
            "Epoch 154: val_loss=0.9582\n",
            "Epoch 155: val_loss=0.9566\n",
            "Epoch 156: val_loss=0.9363\n",
            "Epoch 157: val_loss=0.9516\n",
            "Early stopping triggered.\n",
            "MAE : 0.6868, RMSE: 0.9875, R²: 0.3474\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.7081 ± 0.0428\n",
            "RMSE: 1.1336 ± 0.2533\n",
            "R²  : 0.1374 ± 0.4186\n",
            "\n",
            "=== Финальное обучение на всём train+val ===\n",
            "Final model saved to final_mlp_model.pth\n",
            "\n",
            "=== Загрузка модели из файла и тестирование ===\n",
            "Test MAE : 0.6009\n",
            "Test RMSE: 0.8047\n",
            "Test R²  : 0.5585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Та же модель и параметры но на дескрипторах RDKit"
      ],
      "metadata": {
        "id": "4Znhnzq6QWvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На другом датасете rdkit. Ниже два кода с двумя комбинациями параметров."
      ],
      "metadata": {
        "id": "sOSLsRpyBkG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "df = pd.read_csv('/content/RDKit_nonagg_pca_processed.csv')\n",
        "X = df.drop(columns=['pIC50']).values.astype(np.float32)\n",
        "y = df['pIC50'].values.astype(np.float32)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=10, max_epochs=100):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            # если нет валидации, просто сохраняем последнюю модель\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32, shuffle=False)\n",
        "\n",
        "        model = MLP(input_dim=X_train.shape[1]).to(device)\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "print(\"\\n=== Финальное обучение на всём train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# сохраняем финальную модель\n",
        "model_path = 'final_mlp_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# загрузка модели из файла и тест\n",
        "print(\"\\n=== Загрузка модели из файла и тестирование ===\")\n",
        "loaded_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q9raVvTBYmA",
        "outputId": "576d93c7-c2d7-4c5c-c026-7a7ccf5e836b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=3.5534\n",
            "Epoch 2: val_loss=2.9390\n",
            "Epoch 3: val_loss=2.6685\n",
            "Epoch 4: val_loss=2.5458\n",
            "Epoch 5: val_loss=2.5130\n",
            "Epoch 6: val_loss=2.4303\n",
            "Epoch 7: val_loss=2.3991\n",
            "Epoch 8: val_loss=2.4348\n",
            "Epoch 9: val_loss=2.4415\n",
            "Epoch 10: val_loss=2.3084\n",
            "Epoch 11: val_loss=2.2556\n",
            "Epoch 12: val_loss=2.1886\n",
            "Epoch 13: val_loss=2.2903\n",
            "Epoch 14: val_loss=2.3667\n",
            "Epoch 15: val_loss=2.1256\n",
            "Epoch 16: val_loss=2.1702\n",
            "Epoch 17: val_loss=2.2289\n",
            "Epoch 18: val_loss=2.1823\n",
            "Epoch 19: val_loss=2.1711\n",
            "Epoch 20: val_loss=2.2563\n",
            "Epoch 21: val_loss=2.1966\n",
            "Epoch 22: val_loss=2.1325\n",
            "Epoch 23: val_loss=2.2420\n",
            "Epoch 24: val_loss=2.1634\n",
            "Epoch 25: val_loss=2.1350\n",
            "Early stopping triggered.\n",
            "MAE : 0.8320, RMSE: 1.4617, R²: -0.3883\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=2.6962\n",
            "Epoch 2: val_loss=1.8456\n",
            "Epoch 3: val_loss=1.6169\n",
            "Epoch 4: val_loss=1.5147\n",
            "Epoch 5: val_loss=1.4401\n",
            "Epoch 6: val_loss=1.3969\n",
            "Epoch 7: val_loss=1.3483\n",
            "Epoch 8: val_loss=1.3082\n",
            "Epoch 9: val_loss=1.3237\n",
            "Epoch 10: val_loss=1.2735\n",
            "Epoch 11: val_loss=1.2229\n",
            "Epoch 12: val_loss=1.2246\n",
            "Epoch 13: val_loss=1.2246\n",
            "Epoch 14: val_loss=1.2385\n",
            "Epoch 15: val_loss=1.2047\n",
            "Epoch 16: val_loss=1.2145\n",
            "Epoch 17: val_loss=1.1999\n",
            "Epoch 18: val_loss=1.1330\n",
            "Epoch 19: val_loss=1.1838\n",
            "Epoch 20: val_loss=1.1621\n",
            "Epoch 21: val_loss=1.1119\n",
            "Epoch 22: val_loss=1.1264\n",
            "Epoch 23: val_loss=1.1300\n",
            "Epoch 24: val_loss=1.1292\n",
            "Epoch 25: val_loss=1.1604\n",
            "Epoch 26: val_loss=1.1066\n",
            "Epoch 27: val_loss=1.1338\n",
            "Epoch 28: val_loss=1.1582\n",
            "Epoch 29: val_loss=1.0978\n",
            "Epoch 30: val_loss=1.1026\n",
            "Epoch 31: val_loss=1.1593\n",
            "Epoch 32: val_loss=1.0902\n",
            "Epoch 33: val_loss=1.1199\n",
            "Epoch 34: val_loss=1.1331\n",
            "Epoch 35: val_loss=1.0768\n",
            "Epoch 36: val_loss=1.1403\n",
            "Epoch 37: val_loss=1.1271\n",
            "Epoch 38: val_loss=1.1001\n",
            "Epoch 39: val_loss=1.1017\n",
            "Epoch 40: val_loss=1.0896\n",
            "Epoch 41: val_loss=1.1062\n",
            "Epoch 42: val_loss=1.0862\n",
            "Epoch 43: val_loss=1.0752\n",
            "Epoch 44: val_loss=1.1284\n",
            "Epoch 45: val_loss=1.0853\n",
            "Epoch 46: val_loss=1.0661\n",
            "Epoch 47: val_loss=1.0321\n",
            "Epoch 48: val_loss=1.0343\n",
            "Epoch 49: val_loss=1.0231\n",
            "Epoch 50: val_loss=1.1147\n",
            "Epoch 51: val_loss=1.1176\n",
            "Epoch 52: val_loss=1.0873\n",
            "Epoch 53: val_loss=1.1037\n",
            "Epoch 54: val_loss=1.0898\n",
            "Epoch 55: val_loss=1.1362\n",
            "Epoch 56: val_loss=1.0495\n",
            "Epoch 57: val_loss=1.0448\n",
            "Epoch 58: val_loss=1.1180\n",
            "Epoch 59: val_loss=1.0953\n",
            "Early stopping triggered.\n",
            "MAE : 0.7721, RMSE: 1.0181, R²: 0.2667\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=3.0612\n",
            "Epoch 2: val_loss=1.7493\n",
            "Epoch 3: val_loss=1.5450\n",
            "Epoch 4: val_loss=1.4738\n",
            "Epoch 5: val_loss=1.3804\n",
            "Epoch 6: val_loss=1.3569\n",
            "Epoch 7: val_loss=1.3019\n",
            "Epoch 8: val_loss=1.2795\n",
            "Epoch 9: val_loss=1.2482\n",
            "Epoch 10: val_loss=1.2543\n",
            "Epoch 11: val_loss=1.2460\n",
            "Epoch 12: val_loss=1.1649\n",
            "Epoch 13: val_loss=1.2029\n",
            "Epoch 14: val_loss=1.1611\n",
            "Epoch 15: val_loss=1.1383\n",
            "Epoch 16: val_loss=1.1263\n",
            "Epoch 17: val_loss=1.1229\n",
            "Epoch 18: val_loss=1.1271\n",
            "Epoch 19: val_loss=1.1209\n",
            "Epoch 20: val_loss=1.1124\n",
            "Epoch 21: val_loss=1.1000\n",
            "Epoch 22: val_loss=1.1179\n",
            "Epoch 23: val_loss=1.1221\n",
            "Epoch 24: val_loss=1.1205\n",
            "Epoch 25: val_loss=1.1106\n",
            "Epoch 26: val_loss=1.0590\n",
            "Epoch 27: val_loss=1.0655\n",
            "Epoch 28: val_loss=1.0763\n",
            "Epoch 29: val_loss=1.0537\n",
            "Epoch 30: val_loss=1.0671\n",
            "Epoch 31: val_loss=1.0512\n",
            "Epoch 32: val_loss=1.0542\n",
            "Epoch 33: val_loss=1.0625\n",
            "Epoch 34: val_loss=1.0829\n",
            "Epoch 35: val_loss=1.0638\n",
            "Epoch 36: val_loss=1.0595\n",
            "Epoch 37: val_loss=1.0628\n",
            "Epoch 38: val_loss=1.0287\n",
            "Epoch 39: val_loss=1.0336\n",
            "Epoch 40: val_loss=1.0587\n",
            "Epoch 41: val_loss=1.0337\n",
            "Epoch 42: val_loss=1.0529\n",
            "Epoch 43: val_loss=1.0423\n",
            "Epoch 44: val_loss=1.0543\n",
            "Epoch 45: val_loss=1.0439\n",
            "Epoch 46: val_loss=1.0142\n",
            "Epoch 47: val_loss=1.0182\n",
            "Epoch 48: val_loss=0.9894\n",
            "Epoch 49: val_loss=1.0502\n",
            "Epoch 50: val_loss=1.0203\n",
            "Epoch 51: val_loss=1.0387\n",
            "Epoch 52: val_loss=1.0346\n",
            "Epoch 53: val_loss=1.0218\n",
            "Epoch 54: val_loss=1.0213\n",
            "Epoch 55: val_loss=1.0735\n",
            "Epoch 56: val_loss=1.0723\n",
            "Epoch 57: val_loss=1.0632\n",
            "Epoch 58: val_loss=1.0333\n",
            "Early stopping triggered.\n",
            "MAE : 0.7543, RMSE: 1.0088, R²: 0.3523\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=2.6626\n",
            "Epoch 2: val_loss=1.6433\n",
            "Epoch 3: val_loss=1.5140\n",
            "Epoch 4: val_loss=1.4259\n",
            "Epoch 5: val_loss=1.3799\n",
            "Epoch 6: val_loss=1.3107\n",
            "Epoch 7: val_loss=1.2939\n",
            "Epoch 8: val_loss=1.2690\n",
            "Epoch 9: val_loss=1.1996\n",
            "Epoch 10: val_loss=1.2276\n",
            "Epoch 11: val_loss=1.1996\n",
            "Epoch 12: val_loss=1.1717\n",
            "Epoch 13: val_loss=1.1817\n",
            "Epoch 14: val_loss=1.1588\n",
            "Epoch 15: val_loss=1.1356\n",
            "Epoch 16: val_loss=1.1650\n",
            "Epoch 17: val_loss=1.1498\n",
            "Epoch 18: val_loss=1.1366\n",
            "Epoch 19: val_loss=1.1308\n",
            "Epoch 20: val_loss=1.1039\n",
            "Epoch 21: val_loss=1.0969\n",
            "Epoch 22: val_loss=1.1065\n",
            "Epoch 23: val_loss=1.1521\n",
            "Epoch 24: val_loss=1.0644\n",
            "Epoch 25: val_loss=1.1547\n",
            "Epoch 26: val_loss=1.0833\n",
            "Epoch 27: val_loss=1.0730\n",
            "Epoch 28: val_loss=1.0542\n",
            "Epoch 29: val_loss=1.0643\n",
            "Epoch 30: val_loss=1.0800\n",
            "Epoch 31: val_loss=1.1063\n",
            "Epoch 32: val_loss=1.1132\n",
            "Epoch 33: val_loss=1.0537\n",
            "Epoch 34: val_loss=1.0849\n",
            "Epoch 35: val_loss=1.0280\n",
            "Epoch 36: val_loss=1.1063\n",
            "Epoch 37: val_loss=1.0649\n",
            "Epoch 38: val_loss=1.0208\n",
            "Epoch 39: val_loss=1.0675\n",
            "Epoch 40: val_loss=1.0256\n",
            "Epoch 41: val_loss=1.0367\n",
            "Epoch 42: val_loss=1.0109\n",
            "Epoch 43: val_loss=1.0405\n",
            "Epoch 44: val_loss=1.0192\n",
            "Epoch 45: val_loss=1.0857\n",
            "Epoch 46: val_loss=1.0430\n",
            "Epoch 47: val_loss=1.0626\n",
            "Epoch 48: val_loss=1.1000\n",
            "Epoch 49: val_loss=1.1073\n",
            "Epoch 50: val_loss=1.1065\n",
            "Epoch 51: val_loss=1.1296\n",
            "Epoch 52: val_loss=1.1454\n",
            "Early stopping triggered.\n",
            "MAE : 0.7792, RMSE: 1.0844, R²: 0.2702\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=3.5962\n",
            "Epoch 2: val_loss=1.8550\n",
            "Epoch 3: val_loss=1.6166\n",
            "Epoch 4: val_loss=1.4745\n",
            "Epoch 5: val_loss=1.4002\n",
            "Epoch 6: val_loss=1.3294\n",
            "Epoch 7: val_loss=1.2991\n",
            "Epoch 8: val_loss=1.2736\n",
            "Epoch 9: val_loss=1.2465\n",
            "Epoch 10: val_loss=1.2563\n",
            "Epoch 11: val_loss=1.2430\n",
            "Epoch 12: val_loss=1.2123\n",
            "Epoch 13: val_loss=1.2312\n",
            "Epoch 14: val_loss=1.1670\n",
            "Epoch 15: val_loss=1.1546\n",
            "Epoch 16: val_loss=1.1765\n",
            "Epoch 17: val_loss=1.1169\n",
            "Epoch 18: val_loss=1.1169\n",
            "Epoch 19: val_loss=1.1382\n",
            "Epoch 20: val_loss=1.1230\n",
            "Epoch 21: val_loss=1.0998\n",
            "Epoch 22: val_loss=1.0950\n",
            "Epoch 23: val_loss=1.0880\n",
            "Epoch 24: val_loss=1.1019\n",
            "Epoch 25: val_loss=1.0999\n",
            "Epoch 26: val_loss=1.0914\n",
            "Epoch 27: val_loss=1.0497\n",
            "Epoch 28: val_loss=1.0790\n",
            "Epoch 29: val_loss=1.0824\n",
            "Epoch 30: val_loss=1.1031\n",
            "Epoch 31: val_loss=1.0694\n",
            "Epoch 32: val_loss=1.0719\n",
            "Epoch 33: val_loss=1.1012\n",
            "Epoch 34: val_loss=1.0406\n",
            "Epoch 35: val_loss=1.1011\n",
            "Epoch 36: val_loss=1.0836\n",
            "Epoch 37: val_loss=1.1092\n",
            "Epoch 38: val_loss=1.0572\n",
            "Epoch 39: val_loss=1.0436\n",
            "Epoch 40: val_loss=1.1094\n",
            "Epoch 41: val_loss=1.0597\n",
            "Epoch 42: val_loss=1.0540\n",
            "Epoch 43: val_loss=1.0826\n",
            "Epoch 44: val_loss=1.0890\n",
            "Early stopping triggered.\n",
            "MAE : 0.7579, RMSE: 1.0463, R²: 0.2972\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.7791 ± 0.0280\n",
            "RMSE: 1.1238 ± 0.1710\n",
            "R²  : 0.1596 ± 0.2757\n",
            "\n",
            "=== Финальное обучение на всём train+val ===\n",
            "Final model saved to final_mlp_model.pth\n",
            "\n",
            "=== Загрузка модели из файла и тестирование ===\n",
            "Test MAE : 0.7209\n",
            "Test RMSE: 1.0539\n",
            "Test R²  : 0.3041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=15, max_epochs=200):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=64, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=64, shuffle=False)\n",
        "\n",
        "        model = MLP(input_dim=X_train.shape[1]).to(device)\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "print(\"\\n=== Финальное обучение на всём train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# сохраняем финальную модель\n",
        "model_path = 'final_mlp_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# загрузка модели из файла и тест\n",
        "print(\"\\n=== Загрузка модели из файла и тестирование ===\")\n",
        "loaded_model = MLP(input_dim=X_trainval.shape[1]).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uS_uXL1B5BG",
        "outputId": "3d763152-566a-4df1-d02f-eae12d2be14b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=7.0923\n",
            "Epoch 2: val_loss=3.5996\n",
            "Epoch 3: val_loss=2.6609\n",
            "Epoch 4: val_loss=2.4363\n",
            "Epoch 5: val_loss=2.2923\n",
            "Epoch 6: val_loss=2.2291\n",
            "Epoch 7: val_loss=2.2986\n",
            "Epoch 8: val_loss=2.1039\n",
            "Epoch 9: val_loss=2.0284\n",
            "Epoch 10: val_loss=1.9729\n",
            "Epoch 11: val_loss=1.9097\n",
            "Epoch 12: val_loss=1.8637\n",
            "Epoch 13: val_loss=1.8075\n",
            "Epoch 14: val_loss=1.8024\n",
            "Epoch 15: val_loss=1.7879\n",
            "Epoch 16: val_loss=1.7695\n",
            "Epoch 17: val_loss=1.7094\n",
            "Epoch 18: val_loss=1.7118\n",
            "Epoch 19: val_loss=1.6742\n",
            "Epoch 20: val_loss=1.6710\n",
            "Epoch 21: val_loss=1.6703\n",
            "Epoch 22: val_loss=1.6578\n",
            "Epoch 23: val_loss=1.7170\n",
            "Epoch 24: val_loss=1.6326\n",
            "Epoch 25: val_loss=1.7184\n",
            "Epoch 26: val_loss=1.6157\n",
            "Epoch 27: val_loss=1.5404\n",
            "Epoch 28: val_loss=1.5462\n",
            "Epoch 29: val_loss=1.5406\n",
            "Epoch 30: val_loss=1.5270\n",
            "Epoch 31: val_loss=1.5441\n",
            "Epoch 32: val_loss=1.4796\n",
            "Epoch 33: val_loss=1.4780\n",
            "Epoch 34: val_loss=1.4998\n",
            "Epoch 35: val_loss=1.5139\n",
            "Epoch 36: val_loss=1.4890\n",
            "Epoch 37: val_loss=1.5076\n",
            "Epoch 38: val_loss=1.4949\n",
            "Epoch 39: val_loss=1.4876\n",
            "Epoch 40: val_loss=1.5188\n",
            "Epoch 41: val_loss=1.6155\n",
            "Epoch 42: val_loss=1.4613\n",
            "Epoch 43: val_loss=1.4931\n",
            "Epoch 44: val_loss=1.4117\n",
            "Epoch 45: val_loss=1.3954\n",
            "Epoch 46: val_loss=1.3926\n",
            "Epoch 47: val_loss=1.3739\n",
            "Epoch 48: val_loss=1.3698\n",
            "Epoch 49: val_loss=1.3183\n",
            "Epoch 50: val_loss=1.3345\n",
            "Epoch 51: val_loss=1.3173\n",
            "Epoch 52: val_loss=1.3714\n",
            "Epoch 53: val_loss=1.2849\n",
            "Epoch 54: val_loss=1.3027\n",
            "Epoch 55: val_loss=1.3159\n",
            "Epoch 56: val_loss=1.3662\n",
            "Epoch 57: val_loss=1.2796\n",
            "Epoch 58: val_loss=1.2684\n",
            "Epoch 59: val_loss=1.2613\n",
            "Epoch 60: val_loss=1.2852\n",
            "Epoch 61: val_loss=1.2731\n",
            "Epoch 62: val_loss=1.2550\n",
            "Epoch 63: val_loss=1.2699\n",
            "Epoch 64: val_loss=1.2384\n",
            "Epoch 65: val_loss=1.3096\n",
            "Epoch 66: val_loss=1.2510\n",
            "Epoch 67: val_loss=1.3195\n",
            "Epoch 68: val_loss=1.2470\n",
            "Epoch 69: val_loss=1.2164\n",
            "Epoch 70: val_loss=1.2192\n",
            "Epoch 71: val_loss=1.2111\n",
            "Epoch 72: val_loss=1.2324\n",
            "Epoch 73: val_loss=1.2020\n",
            "Epoch 74: val_loss=1.1643\n",
            "Epoch 75: val_loss=1.1790\n",
            "Epoch 76: val_loss=1.1743\n",
            "Epoch 77: val_loss=1.1765\n",
            "Epoch 78: val_loss=1.1361\n",
            "Epoch 79: val_loss=1.1271\n",
            "Epoch 80: val_loss=1.1635\n",
            "Epoch 81: val_loss=1.1814\n",
            "Epoch 82: val_loss=1.1522\n",
            "Epoch 83: val_loss=1.2084\n",
            "Epoch 84: val_loss=1.1641\n",
            "Epoch 85: val_loss=1.1393\n",
            "Epoch 86: val_loss=1.1106\n",
            "Epoch 87: val_loss=1.0975\n",
            "Epoch 88: val_loss=1.1043\n",
            "Epoch 89: val_loss=1.1321\n",
            "Epoch 90: val_loss=1.1293\n",
            "Epoch 91: val_loss=1.1504\n",
            "Epoch 92: val_loss=1.0909\n",
            "Epoch 93: val_loss=1.0586\n",
            "Epoch 94: val_loss=1.0607\n",
            "Epoch 95: val_loss=1.0634\n",
            "Epoch 96: val_loss=1.0695\n",
            "Epoch 97: val_loss=1.0615\n",
            "Epoch 98: val_loss=1.0749\n",
            "Epoch 99: val_loss=1.0276\n",
            "Epoch 100: val_loss=1.0220\n",
            "Epoch 101: val_loss=1.0501\n",
            "Epoch 102: val_loss=1.0285\n",
            "Epoch 103: val_loss=1.0375\n",
            "Epoch 104: val_loss=1.0552\n",
            "Epoch 105: val_loss=1.0104\n",
            "Epoch 106: val_loss=1.0611\n",
            "Epoch 107: val_loss=1.0297\n",
            "Epoch 108: val_loss=1.0346\n",
            "Epoch 109: val_loss=1.0343\n",
            "Epoch 110: val_loss=1.0232\n",
            "Epoch 111: val_loss=1.0457\n",
            "Epoch 112: val_loss=1.0474\n",
            "Epoch 113: val_loss=1.0105\n",
            "Epoch 114: val_loss=0.9856\n",
            "Epoch 115: val_loss=1.0119\n",
            "Epoch 116: val_loss=0.9954\n",
            "Epoch 117: val_loss=1.0259\n",
            "Epoch 118: val_loss=1.0008\n",
            "Epoch 119: val_loss=1.0069\n",
            "Epoch 120: val_loss=1.0082\n",
            "Epoch 121: val_loss=1.0072\n",
            "Epoch 122: val_loss=0.9934\n",
            "Epoch 123: val_loss=0.9651\n",
            "Epoch 124: val_loss=0.9934\n",
            "Epoch 125: val_loss=0.9643\n",
            "Epoch 126: val_loss=0.9513\n",
            "Epoch 127: val_loss=0.9632\n",
            "Epoch 128: val_loss=0.9778\n",
            "Epoch 129: val_loss=0.9642\n",
            "Epoch 130: val_loss=0.9807\n",
            "Epoch 131: val_loss=0.9805\n",
            "Epoch 132: val_loss=0.9822\n",
            "Epoch 133: val_loss=0.9835\n",
            "Epoch 134: val_loss=0.9864\n",
            "Epoch 135: val_loss=1.0211\n",
            "Epoch 136: val_loss=1.0172\n",
            "Epoch 137: val_loss=0.9904\n",
            "Epoch 138: val_loss=1.0040\n",
            "Epoch 139: val_loss=0.9781\n",
            "Epoch 140: val_loss=0.9699\n",
            "Epoch 141: val_loss=0.9485\n",
            "Epoch 142: val_loss=0.9671\n",
            "Epoch 143: val_loss=0.9635\n",
            "Epoch 144: val_loss=0.9602\n",
            "Epoch 145: val_loss=0.9699\n",
            "Epoch 146: val_loss=1.0069\n",
            "Epoch 147: val_loss=0.9339\n",
            "Epoch 148: val_loss=0.9379\n",
            "Epoch 149: val_loss=0.9441\n",
            "Epoch 150: val_loss=0.9278\n",
            "Epoch 151: val_loss=0.9429\n",
            "Epoch 152: val_loss=0.9657\n",
            "Epoch 153: val_loss=0.9896\n",
            "Epoch 154: val_loss=0.9582\n",
            "Epoch 155: val_loss=1.0133\n",
            "Epoch 156: val_loss=0.9382\n",
            "Epoch 157: val_loss=0.9486\n",
            "Epoch 158: val_loss=0.9802\n",
            "Epoch 159: val_loss=0.9286\n",
            "Epoch 160: val_loss=0.9206\n",
            "Epoch 161: val_loss=0.9288\n",
            "Epoch 162: val_loss=0.9139\n",
            "Epoch 163: val_loss=0.9263\n",
            "Epoch 164: val_loss=0.9414\n",
            "Epoch 165: val_loss=0.9148\n",
            "Epoch 166: val_loss=0.9324\n",
            "Epoch 167: val_loss=0.9349\n",
            "Epoch 168: val_loss=0.9125\n",
            "Epoch 169: val_loss=0.9801\n",
            "Epoch 170: val_loss=0.9256\n",
            "Epoch 171: val_loss=0.9482\n",
            "Epoch 172: val_loss=0.9429\n",
            "Epoch 173: val_loss=1.0241\n",
            "Epoch 174: val_loss=0.9346\n",
            "Epoch 175: val_loss=0.9648\n",
            "Epoch 176: val_loss=0.9351\n",
            "Epoch 177: val_loss=0.9655\n",
            "Epoch 178: val_loss=0.9346\n",
            "Epoch 179: val_loss=1.0058\n",
            "Epoch 180: val_loss=0.9324\n",
            "Epoch 181: val_loss=0.9232\n",
            "Epoch 182: val_loss=0.9216\n",
            "Epoch 183: val_loss=0.9252\n",
            "Early stopping triggered.\n",
            "MAE : 0.6673, RMSE: 0.9699, R²: 0.3888\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=7.1569\n",
            "Epoch 2: val_loss=3.1767\n",
            "Epoch 3: val_loss=2.1644\n",
            "Epoch 4: val_loss=1.7797\n",
            "Epoch 5: val_loss=1.6523\n",
            "Epoch 6: val_loss=1.5620\n",
            "Epoch 7: val_loss=1.4957\n",
            "Epoch 8: val_loss=1.4297\n",
            "Epoch 9: val_loss=1.4138\n",
            "Epoch 10: val_loss=1.3642\n",
            "Epoch 11: val_loss=1.3299\n",
            "Epoch 12: val_loss=1.3220\n",
            "Epoch 13: val_loss=1.3621\n",
            "Epoch 14: val_loss=1.2688\n",
            "Epoch 15: val_loss=1.2234\n",
            "Epoch 16: val_loss=1.2228\n",
            "Epoch 17: val_loss=1.2046\n",
            "Epoch 18: val_loss=1.2018\n",
            "Epoch 19: val_loss=1.1641\n",
            "Epoch 20: val_loss=1.1982\n",
            "Epoch 21: val_loss=1.1586\n",
            "Epoch 22: val_loss=1.1277\n",
            "Epoch 23: val_loss=1.1110\n",
            "Epoch 24: val_loss=1.0926\n",
            "Epoch 25: val_loss=1.1176\n",
            "Epoch 26: val_loss=1.0947\n",
            "Epoch 27: val_loss=1.0846\n",
            "Epoch 28: val_loss=1.0882\n",
            "Epoch 29: val_loss=1.1245\n",
            "Epoch 30: val_loss=1.1350\n",
            "Epoch 31: val_loss=1.0842\n",
            "Epoch 32: val_loss=1.0520\n",
            "Epoch 33: val_loss=1.0637\n",
            "Epoch 34: val_loss=1.0754\n",
            "Epoch 35: val_loss=1.1048\n",
            "Epoch 36: val_loss=1.0120\n",
            "Epoch 37: val_loss=1.0219\n",
            "Epoch 38: val_loss=1.0974\n",
            "Epoch 39: val_loss=1.0324\n",
            "Epoch 40: val_loss=1.0079\n",
            "Epoch 41: val_loss=1.0464\n",
            "Epoch 42: val_loss=1.0196\n",
            "Epoch 43: val_loss=1.0242\n",
            "Epoch 44: val_loss=0.9932\n",
            "Epoch 45: val_loss=1.0296\n",
            "Epoch 46: val_loss=1.0104\n",
            "Epoch 47: val_loss=0.9977\n",
            "Epoch 48: val_loss=1.0005\n",
            "Epoch 49: val_loss=0.9714\n",
            "Epoch 50: val_loss=1.0271\n",
            "Epoch 51: val_loss=0.9732\n",
            "Epoch 52: val_loss=1.0242\n",
            "Epoch 53: val_loss=0.9546\n",
            "Epoch 54: val_loss=0.9636\n",
            "Epoch 55: val_loss=0.9781\n",
            "Epoch 56: val_loss=0.9313\n",
            "Epoch 57: val_loss=0.9420\n",
            "Epoch 58: val_loss=0.9322\n",
            "Epoch 59: val_loss=0.9569\n",
            "Epoch 60: val_loss=1.0019\n",
            "Epoch 61: val_loss=0.9363\n",
            "Epoch 62: val_loss=0.9307\n",
            "Epoch 63: val_loss=0.9462\n",
            "Epoch 64: val_loss=0.9385\n",
            "Epoch 65: val_loss=0.9288\n",
            "Epoch 66: val_loss=0.9585\n",
            "Epoch 67: val_loss=1.0061\n",
            "Epoch 68: val_loss=0.9355\n",
            "Epoch 69: val_loss=0.9334\n",
            "Epoch 70: val_loss=1.0110\n",
            "Epoch 71: val_loss=0.9191\n",
            "Epoch 72: val_loss=0.9222\n",
            "Epoch 73: val_loss=0.9448\n",
            "Epoch 74: val_loss=0.9337\n",
            "Epoch 75: val_loss=0.8976\n",
            "Epoch 76: val_loss=0.9877\n",
            "Epoch 77: val_loss=0.8914\n",
            "Epoch 78: val_loss=0.9271\n",
            "Epoch 79: val_loss=0.9261\n",
            "Epoch 80: val_loss=0.9311\n",
            "Epoch 81: val_loss=0.8760\n",
            "Epoch 82: val_loss=0.8789\n",
            "Epoch 83: val_loss=0.8749\n",
            "Epoch 84: val_loss=0.8913\n",
            "Epoch 85: val_loss=0.8665\n",
            "Epoch 86: val_loss=0.8863\n",
            "Epoch 87: val_loss=0.8792\n",
            "Epoch 88: val_loss=0.8589\n",
            "Epoch 89: val_loss=0.8544\n",
            "Epoch 90: val_loss=0.8562\n",
            "Epoch 91: val_loss=0.8513\n",
            "Epoch 92: val_loss=0.8601\n",
            "Epoch 93: val_loss=0.8678\n",
            "Epoch 94: val_loss=0.8612\n",
            "Epoch 95: val_loss=0.9311\n",
            "Epoch 96: val_loss=0.8691\n",
            "Epoch 97: val_loss=0.8752\n",
            "Epoch 98: val_loss=0.8292\n",
            "Epoch 99: val_loss=0.8466\n",
            "Epoch 100: val_loss=0.8856\n",
            "Epoch 101: val_loss=0.8586\n",
            "Epoch 102: val_loss=0.8531\n",
            "Epoch 103: val_loss=0.8673\n",
            "Epoch 104: val_loss=0.8421\n",
            "Epoch 105: val_loss=0.8589\n",
            "Epoch 106: val_loss=0.8507\n",
            "Epoch 107: val_loss=0.8474\n",
            "Epoch 108: val_loss=0.8761\n",
            "Epoch 109: val_loss=0.8260\n",
            "Epoch 110: val_loss=0.8413\n",
            "Epoch 111: val_loss=0.8506\n",
            "Epoch 112: val_loss=0.9250\n",
            "Epoch 113: val_loss=0.9039\n",
            "Epoch 114: val_loss=0.8363\n",
            "Epoch 115: val_loss=0.9110\n",
            "Epoch 116: val_loss=0.9867\n",
            "Epoch 117: val_loss=0.8251\n",
            "Epoch 118: val_loss=0.8814\n",
            "Epoch 119: val_loss=0.8386\n",
            "Epoch 120: val_loss=0.9195\n",
            "Epoch 121: val_loss=0.8487\n",
            "Epoch 122: val_loss=0.8214\n",
            "Epoch 123: val_loss=0.8202\n",
            "Epoch 124: val_loss=0.8239\n",
            "Epoch 125: val_loss=0.8249\n",
            "Epoch 126: val_loss=0.8033\n",
            "Epoch 127: val_loss=0.9131\n",
            "Epoch 128: val_loss=0.8203\n",
            "Epoch 129: val_loss=0.8635\n",
            "Epoch 130: val_loss=0.8245\n",
            "Epoch 131: val_loss=0.8291\n",
            "Epoch 132: val_loss=0.8422\n",
            "Epoch 133: val_loss=0.8088\n",
            "Epoch 134: val_loss=0.7974\n",
            "Epoch 135: val_loss=0.8450\n",
            "Epoch 136: val_loss=0.8048\n",
            "Epoch 137: val_loss=0.8047\n",
            "Epoch 138: val_loss=0.8435\n",
            "Epoch 139: val_loss=0.8082\n",
            "Epoch 140: val_loss=0.8054\n",
            "Epoch 141: val_loss=0.8184\n",
            "Epoch 142: val_loss=0.8385\n",
            "Epoch 143: val_loss=0.7877\n",
            "Epoch 144: val_loss=0.9321\n",
            "Epoch 145: val_loss=0.8575\n",
            "Epoch 146: val_loss=0.8067\n",
            "Epoch 147: val_loss=0.7896\n",
            "Epoch 148: val_loss=0.9226\n",
            "Epoch 149: val_loss=0.8432\n",
            "Epoch 150: val_loss=0.8085\n",
            "Epoch 151: val_loss=0.7942\n",
            "Epoch 152: val_loss=0.8027\n",
            "Epoch 153: val_loss=0.8222\n",
            "Epoch 154: val_loss=0.7829\n",
            "Epoch 155: val_loss=0.8354\n",
            "Epoch 156: val_loss=0.7934\n",
            "Epoch 157: val_loss=0.7882\n",
            "Epoch 158: val_loss=0.8031\n",
            "Epoch 159: val_loss=0.7998\n",
            "Epoch 160: val_loss=0.7816\n",
            "Epoch 161: val_loss=0.7875\n",
            "Epoch 162: val_loss=0.8334\n",
            "Epoch 163: val_loss=0.8809\n",
            "Epoch 164: val_loss=0.8168\n",
            "Epoch 165: val_loss=0.7980\n",
            "Epoch 166: val_loss=0.8007\n",
            "Epoch 167: val_loss=0.8384\n",
            "Epoch 168: val_loss=0.8235\n",
            "Epoch 169: val_loss=0.8016\n",
            "Epoch 170: val_loss=0.8261\n",
            "Epoch 171: val_loss=0.8179\n",
            "Epoch 172: val_loss=0.7796\n",
            "Epoch 173: val_loss=0.8246\n",
            "Epoch 174: val_loss=0.7845\n",
            "Epoch 175: val_loss=0.8116\n",
            "Epoch 176: val_loss=0.7888\n",
            "Epoch 177: val_loss=0.8044\n",
            "Epoch 178: val_loss=0.8089\n",
            "Epoch 179: val_loss=0.8032\n",
            "Epoch 180: val_loss=0.7949\n",
            "Epoch 181: val_loss=0.7610\n",
            "Epoch 182: val_loss=0.7901\n",
            "Epoch 183: val_loss=0.7820\n",
            "Epoch 184: val_loss=0.8158\n",
            "Epoch 185: val_loss=0.8399\n",
            "Epoch 186: val_loss=0.8080\n",
            "Epoch 187: val_loss=0.7913\n",
            "Epoch 188: val_loss=0.8239\n",
            "Epoch 189: val_loss=0.7770\n",
            "Epoch 190: val_loss=0.7816\n",
            "Epoch 191: val_loss=0.7780\n",
            "Epoch 192: val_loss=0.8088\n",
            "Epoch 193: val_loss=0.8266\n",
            "Epoch 194: val_loss=0.8014\n",
            "Epoch 195: val_loss=0.8094\n",
            "Epoch 196: val_loss=0.7839\n",
            "Early stopping triggered.\n",
            "MAE : 0.6605, RMSE: 0.8792, R²: 0.4532\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=6.7806\n",
            "Epoch 2: val_loss=3.2899\n",
            "Epoch 3: val_loss=2.2382\n",
            "Epoch 4: val_loss=1.8793\n",
            "Epoch 5: val_loss=1.7518\n",
            "Epoch 6: val_loss=1.6940\n",
            "Epoch 7: val_loss=1.6107\n",
            "Epoch 8: val_loss=1.5473\n",
            "Epoch 9: val_loss=1.5016\n",
            "Epoch 10: val_loss=1.4430\n",
            "Epoch 11: val_loss=1.4527\n",
            "Epoch 12: val_loss=1.3634\n",
            "Epoch 13: val_loss=1.3855\n",
            "Epoch 14: val_loss=1.3256\n",
            "Epoch 15: val_loss=1.2983\n",
            "Epoch 16: val_loss=1.2438\n",
            "Epoch 17: val_loss=1.2501\n",
            "Epoch 18: val_loss=1.2048\n",
            "Epoch 19: val_loss=1.2227\n",
            "Epoch 20: val_loss=1.1709\n",
            "Epoch 21: val_loss=1.1745\n",
            "Epoch 22: val_loss=1.1449\n",
            "Epoch 23: val_loss=1.1898\n",
            "Epoch 24: val_loss=1.1423\n",
            "Epoch 25: val_loss=1.1311\n",
            "Epoch 26: val_loss=1.1094\n",
            "Epoch 27: val_loss=1.1053\n",
            "Epoch 28: val_loss=1.0754\n",
            "Epoch 29: val_loss=1.0854\n",
            "Epoch 30: val_loss=1.0663\n",
            "Epoch 31: val_loss=1.0690\n",
            "Epoch 32: val_loss=1.0570\n",
            "Epoch 33: val_loss=1.0337\n",
            "Epoch 34: val_loss=1.0742\n",
            "Epoch 35: val_loss=1.0591\n",
            "Epoch 36: val_loss=1.0394\n",
            "Epoch 37: val_loss=1.0246\n",
            "Epoch 38: val_loss=1.0132\n",
            "Epoch 39: val_loss=1.0140\n",
            "Epoch 40: val_loss=1.0367\n",
            "Epoch 41: val_loss=0.9909\n",
            "Epoch 42: val_loss=0.9949\n",
            "Epoch 43: val_loss=1.0114\n",
            "Epoch 44: val_loss=1.0058\n",
            "Epoch 45: val_loss=0.9850\n",
            "Epoch 46: val_loss=0.9688\n",
            "Epoch 47: val_loss=0.9818\n",
            "Epoch 48: val_loss=0.9970\n",
            "Epoch 49: val_loss=0.9962\n",
            "Epoch 50: val_loss=0.9758\n",
            "Epoch 51: val_loss=1.0008\n",
            "Epoch 52: val_loss=0.9816\n",
            "Epoch 53: val_loss=0.9788\n",
            "Epoch 54: val_loss=0.9628\n",
            "Epoch 55: val_loss=0.9866\n",
            "Epoch 56: val_loss=0.9694\n",
            "Epoch 57: val_loss=0.9440\n",
            "Epoch 58: val_loss=0.9561\n",
            "Epoch 59: val_loss=0.9356\n",
            "Epoch 60: val_loss=0.9306\n",
            "Epoch 61: val_loss=1.0193\n",
            "Epoch 62: val_loss=0.9189\n",
            "Epoch 63: val_loss=0.9147\n",
            "Epoch 64: val_loss=0.9165\n",
            "Epoch 65: val_loss=0.9627\n",
            "Epoch 66: val_loss=0.9326\n",
            "Epoch 67: val_loss=0.9493\n",
            "Epoch 68: val_loss=0.9104\n",
            "Epoch 69: val_loss=0.9171\n",
            "Epoch 70: val_loss=0.9043\n",
            "Epoch 71: val_loss=0.9117\n",
            "Epoch 72: val_loss=0.8998\n",
            "Epoch 73: val_loss=0.9057\n",
            "Epoch 74: val_loss=0.9077\n",
            "Epoch 75: val_loss=0.9182\n",
            "Epoch 76: val_loss=0.8990\n",
            "Epoch 77: val_loss=0.9237\n",
            "Epoch 78: val_loss=0.9081\n",
            "Epoch 79: val_loss=0.9270\n",
            "Epoch 80: val_loss=0.9993\n",
            "Epoch 81: val_loss=0.8884\n",
            "Epoch 82: val_loss=0.8909\n",
            "Epoch 83: val_loss=0.9045\n",
            "Epoch 84: val_loss=0.8874\n",
            "Epoch 85: val_loss=0.9172\n",
            "Epoch 86: val_loss=0.8823\n",
            "Epoch 87: val_loss=0.9043\n",
            "Epoch 88: val_loss=0.9049\n",
            "Epoch 89: val_loss=0.8886\n",
            "Epoch 90: val_loss=0.8921\n",
            "Epoch 91: val_loss=0.9238\n",
            "Epoch 92: val_loss=0.9279\n",
            "Epoch 93: val_loss=0.8901\n",
            "Epoch 94: val_loss=0.8988\n",
            "Epoch 95: val_loss=0.9093\n",
            "Epoch 96: val_loss=0.9127\n",
            "Epoch 97: val_loss=0.9287\n",
            "Epoch 98: val_loss=0.8853\n",
            "Epoch 99: val_loss=0.8875\n",
            "Epoch 100: val_loss=0.8847\n",
            "Epoch 101: val_loss=0.8892\n",
            "Early stopping triggered.\n",
            "MAE : 0.7123, RMSE: 0.9480, R²: 0.4280\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=6.8225\n",
            "Epoch 2: val_loss=3.2116\n",
            "Epoch 3: val_loss=2.1875\n",
            "Epoch 4: val_loss=1.8227\n",
            "Epoch 5: val_loss=1.6833\n",
            "Epoch 6: val_loss=1.6015\n",
            "Epoch 7: val_loss=1.5292\n",
            "Epoch 8: val_loss=1.4893\n",
            "Epoch 9: val_loss=1.4654\n",
            "Epoch 10: val_loss=1.4314\n",
            "Epoch 11: val_loss=1.3944\n",
            "Epoch 12: val_loss=1.3801\n",
            "Epoch 13: val_loss=1.3556\n",
            "Epoch 14: val_loss=1.3358\n",
            "Epoch 15: val_loss=1.3239\n",
            "Epoch 16: val_loss=1.3105\n",
            "Epoch 17: val_loss=1.2949\n",
            "Epoch 18: val_loss=1.2420\n",
            "Epoch 19: val_loss=1.2371\n",
            "Epoch 20: val_loss=1.2225\n",
            "Epoch 21: val_loss=1.2397\n",
            "Epoch 22: val_loss=1.2396\n",
            "Epoch 23: val_loss=1.1987\n",
            "Epoch 24: val_loss=1.1810\n",
            "Epoch 25: val_loss=1.1896\n",
            "Epoch 26: val_loss=1.1863\n",
            "Epoch 27: val_loss=1.1740\n",
            "Epoch 28: val_loss=1.1664\n",
            "Epoch 29: val_loss=1.1326\n",
            "Epoch 30: val_loss=1.1595\n",
            "Epoch 31: val_loss=1.1414\n",
            "Epoch 32: val_loss=1.1230\n",
            "Epoch 33: val_loss=1.1434\n",
            "Epoch 34: val_loss=1.1271\n",
            "Epoch 35: val_loss=1.0979\n",
            "Epoch 36: val_loss=1.1415\n",
            "Epoch 37: val_loss=1.1263\n",
            "Epoch 38: val_loss=1.1062\n",
            "Epoch 39: val_loss=1.0848\n",
            "Epoch 40: val_loss=1.1604\n",
            "Epoch 41: val_loss=1.0960\n",
            "Epoch 42: val_loss=1.0868\n",
            "Epoch 43: val_loss=1.0735\n",
            "Epoch 44: val_loss=1.0989\n",
            "Epoch 45: val_loss=1.0788\n",
            "Epoch 46: val_loss=1.0769\n",
            "Epoch 47: val_loss=1.0863\n",
            "Epoch 48: val_loss=1.0384\n",
            "Epoch 49: val_loss=1.0667\n",
            "Epoch 50: val_loss=1.0433\n",
            "Epoch 51: val_loss=1.0651\n",
            "Epoch 52: val_loss=1.0719\n",
            "Epoch 53: val_loss=1.0482\n",
            "Epoch 54: val_loss=1.0674\n",
            "Epoch 55: val_loss=1.0403\n",
            "Epoch 56: val_loss=1.0501\n",
            "Epoch 57: val_loss=1.0541\n",
            "Epoch 58: val_loss=1.0538\n",
            "Epoch 59: val_loss=1.0387\n",
            "Epoch 60: val_loss=1.0688\n",
            "Epoch 61: val_loss=1.0822\n",
            "Epoch 62: val_loss=1.0262\n",
            "Epoch 63: val_loss=1.0633\n",
            "Epoch 64: val_loss=1.0523\n",
            "Epoch 65: val_loss=1.0300\n",
            "Epoch 66: val_loss=1.0148\n",
            "Epoch 67: val_loss=1.0110\n",
            "Epoch 68: val_loss=1.0681\n",
            "Epoch 69: val_loss=1.0223\n",
            "Epoch 70: val_loss=1.0384\n",
            "Epoch 71: val_loss=0.9901\n",
            "Epoch 72: val_loss=1.0155\n",
            "Epoch 73: val_loss=1.0205\n",
            "Epoch 74: val_loss=0.9947\n",
            "Epoch 75: val_loss=1.0199\n",
            "Epoch 76: val_loss=0.9988\n",
            "Epoch 77: val_loss=0.9965\n",
            "Epoch 78: val_loss=1.0071\n",
            "Epoch 79: val_loss=1.0056\n",
            "Epoch 80: val_loss=0.9978\n",
            "Epoch 81: val_loss=1.0150\n",
            "Epoch 82: val_loss=0.9988\n",
            "Epoch 83: val_loss=0.9952\n",
            "Epoch 84: val_loss=0.9935\n",
            "Epoch 85: val_loss=0.9842\n",
            "Epoch 86: val_loss=1.0054\n",
            "Epoch 87: val_loss=1.0023\n",
            "Epoch 88: val_loss=0.9718\n",
            "Epoch 89: val_loss=0.9930\n",
            "Epoch 90: val_loss=0.9606\n",
            "Epoch 91: val_loss=0.9739\n",
            "Epoch 92: val_loss=1.0197\n",
            "Epoch 93: val_loss=0.9613\n",
            "Epoch 94: val_loss=0.9728\n",
            "Epoch 95: val_loss=0.9606\n",
            "Epoch 96: val_loss=0.9639\n",
            "Epoch 97: val_loss=0.9456\n",
            "Epoch 98: val_loss=0.9975\n",
            "Epoch 99: val_loss=0.9816\n",
            "Epoch 100: val_loss=0.9660\n",
            "Epoch 101: val_loss=0.9472\n",
            "Epoch 102: val_loss=0.9390\n",
            "Epoch 103: val_loss=0.9539\n",
            "Epoch 104: val_loss=0.9371\n",
            "Epoch 105: val_loss=1.0240\n",
            "Epoch 106: val_loss=0.9355\n",
            "Epoch 107: val_loss=0.9581\n",
            "Epoch 108: val_loss=0.9301\n",
            "Epoch 109: val_loss=0.9508\n",
            "Epoch 110: val_loss=0.9262\n",
            "Epoch 111: val_loss=0.9307\n",
            "Epoch 112: val_loss=0.9267\n",
            "Epoch 113: val_loss=0.9200\n",
            "Epoch 114: val_loss=0.9131\n",
            "Epoch 115: val_loss=0.9458\n",
            "Epoch 116: val_loss=0.9292\n",
            "Epoch 117: val_loss=0.9475\n",
            "Epoch 118: val_loss=0.9196\n",
            "Epoch 119: val_loss=0.9282\n",
            "Epoch 120: val_loss=0.9425\n",
            "Epoch 121: val_loss=0.9344\n",
            "Epoch 122: val_loss=0.9435\n",
            "Epoch 123: val_loss=0.9375\n",
            "Epoch 124: val_loss=0.9124\n",
            "Epoch 125: val_loss=0.9310\n",
            "Epoch 126: val_loss=0.9250\n",
            "Epoch 127: val_loss=0.9001\n",
            "Epoch 128: val_loss=0.9046\n",
            "Epoch 129: val_loss=0.9167\n",
            "Epoch 130: val_loss=0.9245\n",
            "Epoch 131: val_loss=0.9053\n",
            "Epoch 132: val_loss=0.9286\n",
            "Epoch 133: val_loss=0.9061\n",
            "Epoch 134: val_loss=0.9002\n",
            "Epoch 135: val_loss=0.8974\n",
            "Epoch 136: val_loss=0.8994\n",
            "Epoch 137: val_loss=0.9150\n",
            "Epoch 138: val_loss=0.8945\n",
            "Epoch 139: val_loss=0.8892\n",
            "Epoch 140: val_loss=0.8901\n",
            "Epoch 141: val_loss=0.8951\n",
            "Epoch 142: val_loss=0.8939\n",
            "Epoch 143: val_loss=0.9085\n",
            "Epoch 144: val_loss=0.9037\n",
            "Epoch 145: val_loss=0.8927\n",
            "Epoch 146: val_loss=0.8902\n",
            "Epoch 147: val_loss=0.9025\n",
            "Epoch 148: val_loss=0.8904\n",
            "Epoch 149: val_loss=0.8801\n",
            "Epoch 150: val_loss=0.9547\n",
            "Epoch 151: val_loss=0.9088\n",
            "Epoch 152: val_loss=0.9051\n",
            "Epoch 153: val_loss=0.8929\n",
            "Epoch 154: val_loss=0.8866\n",
            "Epoch 155: val_loss=0.8821\n",
            "Epoch 156: val_loss=0.9064\n",
            "Epoch 157: val_loss=0.8824\n",
            "Epoch 158: val_loss=0.8883\n",
            "Epoch 159: val_loss=0.9037\n",
            "Epoch 160: val_loss=0.8825\n",
            "Epoch 161: val_loss=0.8749\n",
            "Epoch 162: val_loss=0.9266\n",
            "Epoch 163: val_loss=0.8841\n",
            "Epoch 164: val_loss=0.8903\n",
            "Epoch 165: val_loss=0.8655\n",
            "Epoch 166: val_loss=0.8610\n",
            "Epoch 167: val_loss=0.9015\n",
            "Epoch 168: val_loss=0.8665\n",
            "Epoch 169: val_loss=0.8560\n",
            "Epoch 170: val_loss=0.8481\n",
            "Epoch 171: val_loss=0.8797\n",
            "Epoch 172: val_loss=0.8676\n",
            "Epoch 173: val_loss=0.8730\n",
            "Epoch 174: val_loss=0.8934\n",
            "Epoch 175: val_loss=0.8863\n",
            "Epoch 176: val_loss=0.8708\n",
            "Epoch 177: val_loss=0.8863\n",
            "Epoch 178: val_loss=0.8600\n",
            "Epoch 179: val_loss=0.8655\n",
            "Epoch 180: val_loss=0.8736\n",
            "Epoch 181: val_loss=0.8839\n",
            "Epoch 182: val_loss=0.8833\n",
            "Epoch 183: val_loss=0.8750\n",
            "Epoch 184: val_loss=0.8673\n",
            "Epoch 185: val_loss=0.8643\n",
            "Early stopping triggered.\n",
            "MAE : 0.6885, RMSE: 0.9318, R²: 0.4612\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=8.5015\n",
            "Epoch 2: val_loss=3.4932\n",
            "Epoch 3: val_loss=2.4840\n",
            "Epoch 4: val_loss=2.0079\n",
            "Epoch 5: val_loss=1.8046\n",
            "Epoch 6: val_loss=1.7232\n",
            "Epoch 7: val_loss=1.6524\n",
            "Epoch 8: val_loss=1.5704\n",
            "Epoch 9: val_loss=1.5550\n",
            "Epoch 10: val_loss=1.5102\n",
            "Epoch 11: val_loss=1.4521\n",
            "Epoch 12: val_loss=1.4672\n",
            "Epoch 13: val_loss=1.4189\n",
            "Epoch 14: val_loss=1.3900\n",
            "Epoch 15: val_loss=1.3751\n",
            "Epoch 16: val_loss=1.3571\n",
            "Epoch 17: val_loss=1.3527\n",
            "Epoch 18: val_loss=1.3439\n",
            "Epoch 19: val_loss=1.3215\n",
            "Epoch 20: val_loss=1.3162\n",
            "Epoch 21: val_loss=1.3192\n",
            "Epoch 22: val_loss=1.3003\n",
            "Epoch 23: val_loss=1.2889\n",
            "Epoch 24: val_loss=1.2449\n",
            "Epoch 25: val_loss=1.2592\n",
            "Epoch 26: val_loss=1.2875\n",
            "Epoch 27: val_loss=1.2333\n",
            "Epoch 28: val_loss=1.2486\n",
            "Epoch 29: val_loss=1.2468\n",
            "Epoch 30: val_loss=1.2509\n",
            "Epoch 31: val_loss=1.2391\n",
            "Epoch 32: val_loss=1.1939\n",
            "Epoch 33: val_loss=1.1886\n",
            "Epoch 34: val_loss=1.1993\n",
            "Epoch 35: val_loss=1.1853\n",
            "Epoch 36: val_loss=1.1996\n",
            "Epoch 37: val_loss=1.1758\n",
            "Epoch 38: val_loss=1.1635\n",
            "Epoch 39: val_loss=1.1621\n",
            "Epoch 40: val_loss=1.1690\n",
            "Epoch 41: val_loss=1.1441\n",
            "Epoch 42: val_loss=1.1446\n",
            "Epoch 43: val_loss=1.1950\n",
            "Epoch 44: val_loss=1.1678\n",
            "Epoch 45: val_loss=1.1516\n",
            "Epoch 46: val_loss=1.1645\n",
            "Epoch 47: val_loss=1.1521\n",
            "Epoch 48: val_loss=1.1197\n",
            "Epoch 49: val_loss=1.1543\n",
            "Epoch 50: val_loss=1.1159\n",
            "Epoch 51: val_loss=1.1020\n",
            "Epoch 52: val_loss=1.0824\n",
            "Epoch 53: val_loss=1.0972\n",
            "Epoch 54: val_loss=1.0906\n",
            "Epoch 55: val_loss=1.1120\n",
            "Epoch 56: val_loss=1.1276\n",
            "Epoch 57: val_loss=1.0708\n",
            "Epoch 58: val_loss=1.0904\n",
            "Epoch 59: val_loss=1.0880\n",
            "Epoch 60: val_loss=1.1056\n",
            "Epoch 61: val_loss=1.0561\n",
            "Epoch 62: val_loss=1.0485\n",
            "Epoch 63: val_loss=1.1551\n",
            "Epoch 64: val_loss=1.0418\n",
            "Epoch 65: val_loss=1.0457\n",
            "Epoch 66: val_loss=1.1079\n",
            "Epoch 67: val_loss=1.1052\n",
            "Epoch 68: val_loss=1.0781\n",
            "Epoch 69: val_loss=1.1278\n",
            "Epoch 70: val_loss=1.0892\n",
            "Epoch 71: val_loss=1.0528\n",
            "Epoch 72: val_loss=1.0185\n",
            "Epoch 73: val_loss=1.0748\n",
            "Epoch 74: val_loss=1.0901\n",
            "Epoch 75: val_loss=1.0455\n",
            "Epoch 76: val_loss=1.0419\n",
            "Epoch 77: val_loss=1.0559\n",
            "Epoch 78: val_loss=1.0222\n",
            "Epoch 79: val_loss=1.0302\n",
            "Epoch 80: val_loss=1.0599\n",
            "Epoch 81: val_loss=1.0489\n",
            "Epoch 82: val_loss=1.0326\n",
            "Epoch 83: val_loss=1.0503\n",
            "Epoch 84: val_loss=1.0455\n",
            "Epoch 85: val_loss=1.0505\n",
            "Epoch 86: val_loss=1.0509\n",
            "Epoch 87: val_loss=1.0855\n",
            "Early stopping triggered.\n",
            "MAE : 0.7801, RMSE: 1.0207, R²: 0.3311\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.7017 ± 0.0432\n",
            "RMSE: 0.9499 ± 0.0464\n",
            "R²  : 0.4124 ± 0.0479\n",
            "\n",
            "=== Финальное обучение на всём train+val ===\n",
            "Final model saved to final_mlp_model.pth\n",
            "\n",
            "=== Загрузка модели из файла и тестирование ===\n",
            "Test MAE : 0.6542\n",
            "Test RMSE: 0.9180\n",
            "Test R²  : 0.4720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обоснование выбора признаков, модели и параметров\n",
        "\n",
        "\n",
        "В качестве входных признаков используются дескрипторы Mordred.\n",
        "\n",
        "В качестве модели выбрана одномерная сверточная нейросеть (1D-CNN), способная выявлять локальные паттерны в последовательности признаков. Используется Conv1d с ReLU, MaxPool1d, AdaptiveMaxPool1d и Dropout (0.3–0.4).\n",
        "\n",
        "Модель обучается с помощью оптимизатора Adam (lr=0.001) и ранней остановки (patience=10), что позволяет избежать переобучения. Используется 5-кратная кросс-валидация для устойчивой оценки качества. Финальная модель переобучается на всём train+val и сохраняется для тестирования.\n"
      ],
      "metadata": {
        "id": "XR95vuGXQmTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# === Загрузка данных ===\n",
        "df = pd.read_csv('/content/Mordred_nonagg_pca_processed.csv')\n",
        "X = df.drop(columns=['pIC50']).values.astype(np.float32)\n",
        "y = df['pIC50'].values.astype(np.float32)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# === CNN-модель ===\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_len, out_channels=16, kernel_size=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(1, out_channels, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(out_channels, out_channels * 2, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(out_channels * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # -> (batch_size, 1, input_len)\n",
        "        return self.model(x)\n",
        "\n",
        "# === Обучение с ранней остановкой ===\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=10, max_epochs=100):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# === Кросс-валидация ===\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32, shuffle=False)\n",
        "\n",
        "        model = CNN1D(input_len=X_train.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "# === Финальное обучение ===\n",
        "print(\"\\n=== Финальное обучение на train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = CNN1D(input_len=X_trainval.shape[1], out_channels=32, kernel_size=5, dropout=0.2).to(device)\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# === Сохранение модели ===\n",
        "model_path = 'final_cnn_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# === Тестирование ===\n",
        "print(\"\\n=== Загрузка модели и тестирование ===\")\n",
        "loaded_model = CNN1D(input_len=X_trainval.shape[1], out_channels=32, kernel_size=5, dropout=0.2).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jarfxURCCRCO",
        "outputId": "bf93b236-b43e-40fd-a790-9d1ac8d5040a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=8.1758\n",
            "Epoch 2: val_loss=4.1332\n",
            "Epoch 3: val_loss=2.5221\n",
            "Epoch 4: val_loss=1.7465\n",
            "Epoch 5: val_loss=1.5759\n",
            "Epoch 6: val_loss=1.5190\n",
            "Epoch 7: val_loss=1.5173\n",
            "Epoch 8: val_loss=1.4837\n",
            "Epoch 9: val_loss=1.4778\n",
            "Epoch 10: val_loss=1.4790\n",
            "Epoch 11: val_loss=1.4492\n",
            "Epoch 12: val_loss=1.4450\n",
            "Epoch 13: val_loss=1.4543\n",
            "Epoch 14: val_loss=1.4242\n",
            "Epoch 15: val_loss=1.4700\n",
            "Epoch 16: val_loss=1.4104\n",
            "Epoch 17: val_loss=1.4156\n",
            "Epoch 18: val_loss=1.3945\n",
            "Epoch 19: val_loss=1.4013\n",
            "Epoch 20: val_loss=1.3996\n",
            "Epoch 21: val_loss=1.3957\n",
            "Epoch 22: val_loss=1.3776\n",
            "Epoch 23: val_loss=1.4829\n",
            "Epoch 24: val_loss=1.3648\n",
            "Epoch 25: val_loss=1.3598\n",
            "Epoch 26: val_loss=1.3512\n",
            "Epoch 27: val_loss=1.3662\n",
            "Epoch 28: val_loss=1.3420\n",
            "Epoch 29: val_loss=1.3479\n",
            "Epoch 30: val_loss=1.3865\n",
            "Epoch 31: val_loss=1.3335\n",
            "Epoch 32: val_loss=1.3680\n",
            "Epoch 33: val_loss=1.3231\n",
            "Epoch 34: val_loss=1.3104\n",
            "Epoch 35: val_loss=1.3064\n",
            "Epoch 36: val_loss=1.3062\n",
            "Epoch 37: val_loss=1.3254\n",
            "Epoch 38: val_loss=1.3046\n",
            "Epoch 39: val_loss=1.3100\n",
            "Epoch 40: val_loss=1.2912\n",
            "Epoch 41: val_loss=1.2875\n",
            "Epoch 42: val_loss=1.3352\n",
            "Epoch 43: val_loss=1.2971\n",
            "Epoch 44: val_loss=1.3095\n",
            "Epoch 45: val_loss=1.2816\n",
            "Epoch 46: val_loss=1.3009\n",
            "Epoch 47: val_loss=1.2890\n",
            "Epoch 48: val_loss=1.2687\n",
            "Epoch 49: val_loss=1.2593\n",
            "Epoch 50: val_loss=1.2792\n",
            "Epoch 51: val_loss=1.2776\n",
            "Epoch 52: val_loss=1.2618\n",
            "Epoch 53: val_loss=1.2559\n",
            "Epoch 54: val_loss=1.2592\n",
            "Epoch 55: val_loss=1.2568\n",
            "Epoch 56: val_loss=1.2717\n",
            "Epoch 57: val_loss=1.2782\n",
            "Epoch 58: val_loss=1.2583\n",
            "Epoch 59: val_loss=1.2900\n",
            "Epoch 60: val_loss=1.2467\n",
            "Epoch 61: val_loss=1.2392\n",
            "Epoch 62: val_loss=1.2346\n",
            "Epoch 63: val_loss=1.2686\n",
            "Epoch 64: val_loss=1.4695\n",
            "Epoch 65: val_loss=1.2477\n",
            "Epoch 66: val_loss=1.2996\n",
            "Epoch 67: val_loss=1.4415\n",
            "Epoch 68: val_loss=1.2472\n",
            "Epoch 69: val_loss=1.2565\n",
            "Epoch 70: val_loss=1.2575\n",
            "Epoch 71: val_loss=1.3029\n",
            "Epoch 72: val_loss=1.3873\n",
            "Early stopping triggered.\n",
            "MAE : 0.9409, RMSE: 1.1778, R²: 0.0670\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=7.9232\n",
            "Epoch 2: val_loss=2.8607\n",
            "Epoch 3: val_loss=2.0776\n",
            "Epoch 4: val_loss=1.8193\n",
            "Epoch 5: val_loss=1.7153\n",
            "Epoch 6: val_loss=1.6899\n",
            "Epoch 7: val_loss=1.6466\n",
            "Epoch 8: val_loss=1.6398\n",
            "Epoch 9: val_loss=1.6531\n",
            "Epoch 10: val_loss=1.6335\n",
            "Epoch 11: val_loss=1.6111\n",
            "Epoch 12: val_loss=1.5845\n",
            "Epoch 13: val_loss=1.5842\n",
            "Epoch 14: val_loss=1.5769\n",
            "Epoch 15: val_loss=1.5623\n",
            "Epoch 16: val_loss=1.5916\n",
            "Epoch 17: val_loss=1.5404\n",
            "Epoch 18: val_loss=1.5321\n",
            "Epoch 19: val_loss=1.5217\n",
            "Epoch 20: val_loss=1.5244\n",
            "Epoch 21: val_loss=1.5385\n",
            "Epoch 22: val_loss=1.5196\n",
            "Epoch 23: val_loss=1.5347\n",
            "Epoch 24: val_loss=1.5116\n",
            "Epoch 25: val_loss=1.4909\n",
            "Epoch 26: val_loss=1.5134\n",
            "Epoch 27: val_loss=1.4954\n",
            "Epoch 28: val_loss=1.4946\n",
            "Epoch 29: val_loss=1.5346\n",
            "Epoch 30: val_loss=1.5011\n",
            "Epoch 31: val_loss=1.5158\n",
            "Epoch 32: val_loss=1.4734\n",
            "Epoch 33: val_loss=1.4695\n",
            "Epoch 34: val_loss=1.5420\n",
            "Epoch 35: val_loss=1.4650\n",
            "Epoch 36: val_loss=1.4653\n",
            "Epoch 37: val_loss=1.4515\n",
            "Epoch 38: val_loss=1.4671\n",
            "Epoch 39: val_loss=1.4400\n",
            "Epoch 40: val_loss=1.4552\n",
            "Epoch 41: val_loss=1.4308\n",
            "Epoch 42: val_loss=1.4268\n",
            "Epoch 43: val_loss=1.4397\n",
            "Epoch 44: val_loss=1.4716\n",
            "Epoch 45: val_loss=1.3986\n",
            "Epoch 46: val_loss=1.5075\n",
            "Epoch 47: val_loss=1.3976\n",
            "Epoch 48: val_loss=1.4196\n",
            "Epoch 49: val_loss=1.5064\n",
            "Epoch 50: val_loss=1.4358\n",
            "Epoch 51: val_loss=1.3875\n",
            "Epoch 52: val_loss=1.3943\n",
            "Epoch 53: val_loss=1.5262\n",
            "Epoch 54: val_loss=1.4334\n",
            "Epoch 55: val_loss=1.3595\n",
            "Epoch 56: val_loss=1.3744\n",
            "Epoch 57: val_loss=1.4234\n",
            "Epoch 58: val_loss=1.4189\n",
            "Epoch 59: val_loss=1.4093\n",
            "Epoch 60: val_loss=1.5650\n",
            "Epoch 61: val_loss=1.3478\n",
            "Epoch 62: val_loss=1.3706\n",
            "Epoch 63: val_loss=1.4359\n",
            "Epoch 64: val_loss=1.3521\n",
            "Epoch 65: val_loss=1.3706\n",
            "Epoch 66: val_loss=1.3466\n",
            "Epoch 67: val_loss=1.3662\n",
            "Epoch 68: val_loss=1.3419\n",
            "Epoch 69: val_loss=1.3979\n",
            "Epoch 70: val_loss=1.3499\n",
            "Epoch 71: val_loss=1.3728\n",
            "Epoch 72: val_loss=1.3469\n",
            "Epoch 73: val_loss=1.3376\n",
            "Epoch 74: val_loss=1.3483\n",
            "Epoch 75: val_loss=1.3981\n",
            "Epoch 76: val_loss=1.6525\n",
            "Epoch 77: val_loss=1.3399\n",
            "Epoch 78: val_loss=1.3352\n",
            "Epoch 79: val_loss=1.3349\n",
            "Epoch 80: val_loss=1.3736\n",
            "Epoch 81: val_loss=1.3440\n",
            "Epoch 82: val_loss=1.4179\n",
            "Epoch 83: val_loss=1.3084\n",
            "Epoch 84: val_loss=1.3218\n",
            "Epoch 85: val_loss=1.3168\n",
            "Epoch 86: val_loss=1.3233\n",
            "Epoch 87: val_loss=1.3153\n",
            "Epoch 88: val_loss=1.3260\n",
            "Epoch 89: val_loss=1.3233\n",
            "Epoch 90: val_loss=1.3157\n",
            "Epoch 91: val_loss=1.3325\n",
            "Epoch 92: val_loss=1.3229\n",
            "Epoch 93: val_loss=1.3166\n",
            "Early stopping triggered.\n",
            "MAE : 0.9014, RMSE: 1.1474, R²: 0.1975\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=11.8164\n",
            "Epoch 2: val_loss=7.1707\n",
            "Epoch 3: val_loss=3.3563\n",
            "Epoch 4: val_loss=1.9479\n",
            "Epoch 5: val_loss=1.7770\n",
            "Epoch 6: val_loss=1.6787\n",
            "Epoch 7: val_loss=1.6427\n",
            "Epoch 8: val_loss=1.6234\n",
            "Epoch 9: val_loss=1.6576\n",
            "Epoch 10: val_loss=1.6601\n",
            "Epoch 11: val_loss=1.6149\n",
            "Epoch 12: val_loss=1.6348\n",
            "Epoch 13: val_loss=1.5748\n",
            "Epoch 14: val_loss=1.5723\n",
            "Epoch 15: val_loss=1.5760\n",
            "Epoch 16: val_loss=1.5587\n",
            "Epoch 17: val_loss=1.5542\n",
            "Epoch 18: val_loss=1.5551\n",
            "Epoch 19: val_loss=1.5558\n",
            "Epoch 20: val_loss=1.5308\n",
            "Epoch 21: val_loss=1.5189\n",
            "Epoch 22: val_loss=1.5251\n",
            "Epoch 23: val_loss=1.5071\n",
            "Epoch 24: val_loss=1.5218\n",
            "Epoch 25: val_loss=1.5180\n",
            "Epoch 26: val_loss=1.5240\n",
            "Epoch 27: val_loss=1.5110\n",
            "Epoch 28: val_loss=1.4880\n",
            "Epoch 29: val_loss=1.4849\n",
            "Epoch 30: val_loss=1.5066\n",
            "Epoch 31: val_loss=1.4753\n",
            "Epoch 32: val_loss=1.4861\n",
            "Epoch 33: val_loss=1.4643\n",
            "Epoch 34: val_loss=1.4583\n",
            "Epoch 35: val_loss=1.4923\n",
            "Epoch 36: val_loss=1.4594\n",
            "Epoch 37: val_loss=1.4750\n",
            "Epoch 38: val_loss=1.4254\n",
            "Epoch 39: val_loss=1.4268\n",
            "Epoch 40: val_loss=1.4349\n",
            "Epoch 41: val_loss=1.4113\n",
            "Epoch 42: val_loss=1.3975\n",
            "Epoch 43: val_loss=1.3977\n",
            "Epoch 44: val_loss=1.4134\n",
            "Epoch 45: val_loss=1.3918\n",
            "Epoch 46: val_loss=1.3932\n",
            "Epoch 47: val_loss=1.3654\n",
            "Epoch 48: val_loss=1.3672\n",
            "Epoch 49: val_loss=1.3658\n",
            "Epoch 50: val_loss=1.3444\n",
            "Epoch 51: val_loss=1.3908\n",
            "Epoch 52: val_loss=1.3832\n",
            "Epoch 53: val_loss=1.3296\n",
            "Epoch 54: val_loss=1.3618\n",
            "Epoch 55: val_loss=1.4442\n",
            "Epoch 56: val_loss=1.4398\n",
            "Epoch 57: val_loss=1.2909\n",
            "Epoch 58: val_loss=1.4522\n",
            "Epoch 59: val_loss=1.3855\n",
            "Epoch 60: val_loss=1.2862\n",
            "Epoch 61: val_loss=1.2681\n",
            "Epoch 62: val_loss=1.4460\n",
            "Epoch 63: val_loss=1.2953\n",
            "Epoch 64: val_loss=1.2552\n",
            "Epoch 65: val_loss=1.2455\n",
            "Epoch 66: val_loss=1.2449\n",
            "Epoch 67: val_loss=1.2538\n",
            "Epoch 68: val_loss=1.3240\n",
            "Epoch 69: val_loss=1.2392\n",
            "Epoch 70: val_loss=1.2545\n",
            "Epoch 71: val_loss=1.2162\n",
            "Epoch 72: val_loss=1.2186\n",
            "Epoch 73: val_loss=1.2090\n",
            "Epoch 74: val_loss=1.2269\n",
            "Epoch 75: val_loss=1.3054\n",
            "Epoch 76: val_loss=1.2233\n",
            "Epoch 77: val_loss=1.1909\n",
            "Epoch 78: val_loss=1.2480\n",
            "Epoch 79: val_loss=1.2071\n",
            "Epoch 80: val_loss=1.2561\n",
            "Epoch 81: val_loss=1.2732\n",
            "Epoch 82: val_loss=1.2415\n",
            "Epoch 83: val_loss=1.1935\n",
            "Epoch 84: val_loss=1.2103\n",
            "Epoch 85: val_loss=1.3078\n",
            "Epoch 86: val_loss=1.2662\n",
            "Epoch 87: val_loss=1.3454\n",
            "Early stopping triggered.\n",
            "MAE : 0.9261, RMSE: 1.1598, R²: 0.1659\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=17.2880\n",
            "Epoch 2: val_loss=10.2820\n",
            "Epoch 3: val_loss=4.4249\n",
            "Epoch 4: val_loss=2.1464\n",
            "Epoch 5: val_loss=1.8986\n",
            "Epoch 6: val_loss=1.7728\n",
            "Epoch 7: val_loss=1.7012\n",
            "Epoch 8: val_loss=1.6957\n",
            "Epoch 9: val_loss=1.6304\n",
            "Epoch 10: val_loss=1.6177\n",
            "Epoch 11: val_loss=1.5652\n",
            "Epoch 12: val_loss=1.5750\n",
            "Epoch 13: val_loss=1.5619\n",
            "Epoch 14: val_loss=1.5491\n",
            "Epoch 15: val_loss=1.5732\n",
            "Epoch 16: val_loss=1.5000\n",
            "Epoch 17: val_loss=1.5265\n",
            "Epoch 18: val_loss=1.5589\n",
            "Epoch 19: val_loss=1.5955\n",
            "Epoch 20: val_loss=1.6525\n",
            "Epoch 21: val_loss=1.5068\n",
            "Epoch 22: val_loss=1.5323\n",
            "Epoch 23: val_loss=1.5386\n",
            "Epoch 24: val_loss=1.4758\n",
            "Epoch 25: val_loss=1.5611\n",
            "Epoch 26: val_loss=1.5216\n",
            "Epoch 27: val_loss=1.4579\n",
            "Epoch 28: val_loss=1.4850\n",
            "Epoch 29: val_loss=1.5333\n",
            "Epoch 30: val_loss=1.5384\n",
            "Epoch 31: val_loss=1.4975\n",
            "Epoch 32: val_loss=1.4578\n",
            "Epoch 33: val_loss=1.4979\n",
            "Epoch 34: val_loss=1.4388\n",
            "Epoch 35: val_loss=1.5458\n",
            "Epoch 36: val_loss=1.5167\n",
            "Epoch 37: val_loss=1.5974\n",
            "Epoch 38: val_loss=1.4717\n",
            "Epoch 39: val_loss=1.5150\n",
            "Epoch 40: val_loss=1.5355\n",
            "Epoch 41: val_loss=1.4647\n",
            "Epoch 42: val_loss=1.5996\n",
            "Epoch 43: val_loss=1.4870\n",
            "Epoch 44: val_loss=1.5139\n",
            "Early stopping triggered.\n",
            "MAE : 0.9573, RMSE: 1.2306, R²: 0.0434\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=9.8666\n",
            "Epoch 2: val_loss=5.5637\n",
            "Epoch 3: val_loss=3.2398\n",
            "Epoch 4: val_loss=1.9625\n",
            "Epoch 5: val_loss=1.7083\n",
            "Epoch 6: val_loss=1.7578\n",
            "Epoch 7: val_loss=1.6188\n",
            "Epoch 8: val_loss=1.5580\n",
            "Epoch 9: val_loss=1.5233\n",
            "Epoch 10: val_loss=1.5266\n",
            "Epoch 11: val_loss=1.4890\n",
            "Epoch 12: val_loss=1.4942\n",
            "Epoch 13: val_loss=1.5085\n",
            "Epoch 14: val_loss=1.4842\n",
            "Epoch 15: val_loss=1.4845\n",
            "Epoch 16: val_loss=1.4636\n",
            "Epoch 17: val_loss=1.4724\n",
            "Epoch 18: val_loss=1.4709\n",
            "Epoch 19: val_loss=1.4579\n",
            "Epoch 20: val_loss=1.4603\n",
            "Epoch 21: val_loss=1.4777\n",
            "Epoch 22: val_loss=1.4603\n",
            "Epoch 23: val_loss=1.4786\n",
            "Epoch 24: val_loss=1.5207\n",
            "Epoch 25: val_loss=1.4475\n",
            "Epoch 26: val_loss=1.5341\n",
            "Epoch 27: val_loss=1.4951\n",
            "Epoch 28: val_loss=1.4402\n",
            "Epoch 29: val_loss=1.4270\n",
            "Epoch 30: val_loss=1.4466\n",
            "Epoch 31: val_loss=1.4172\n",
            "Epoch 32: val_loss=1.4338\n",
            "Epoch 33: val_loss=1.6172\n",
            "Epoch 34: val_loss=1.5122\n",
            "Epoch 35: val_loss=1.4165\n",
            "Epoch 36: val_loss=1.3977\n",
            "Epoch 37: val_loss=1.4011\n",
            "Epoch 38: val_loss=1.4073\n",
            "Epoch 39: val_loss=1.4544\n",
            "Epoch 40: val_loss=1.3891\n",
            "Epoch 41: val_loss=1.3869\n",
            "Epoch 42: val_loss=1.3773\n",
            "Epoch 43: val_loss=1.4161\n",
            "Epoch 44: val_loss=1.3790\n",
            "Epoch 45: val_loss=1.3808\n",
            "Epoch 46: val_loss=1.3689\n",
            "Epoch 47: val_loss=1.3658\n",
            "Epoch 48: val_loss=1.4185\n",
            "Epoch 49: val_loss=1.3933\n",
            "Epoch 50: val_loss=1.3595\n",
            "Epoch 51: val_loss=1.4939\n",
            "Epoch 52: val_loss=1.3820\n",
            "Epoch 53: val_loss=1.3375\n",
            "Epoch 54: val_loss=1.3971\n",
            "Epoch 55: val_loss=1.3536\n",
            "Epoch 56: val_loss=1.3723\n",
            "Epoch 57: val_loss=1.3441\n",
            "Epoch 58: val_loss=1.3377\n",
            "Epoch 59: val_loss=1.3305\n",
            "Epoch 60: val_loss=1.4033\n",
            "Epoch 61: val_loss=1.3494\n",
            "Epoch 62: val_loss=1.3397\n",
            "Epoch 63: val_loss=1.3267\n",
            "Epoch 64: val_loss=1.3653\n",
            "Epoch 65: val_loss=1.3241\n",
            "Epoch 66: val_loss=1.3244\n",
            "Epoch 67: val_loss=1.3298\n",
            "Epoch 68: val_loss=1.2997\n",
            "Epoch 69: val_loss=1.3424\n",
            "Epoch 70: val_loss=1.3513\n",
            "Epoch 71: val_loss=1.3073\n",
            "Epoch 72: val_loss=1.2948\n",
            "Epoch 73: val_loss=1.2987\n",
            "Epoch 74: val_loss=1.3309\n",
            "Epoch 75: val_loss=1.2819\n",
            "Epoch 76: val_loss=1.3097\n",
            "Epoch 77: val_loss=1.3606\n",
            "Epoch 78: val_loss=1.3643\n",
            "Epoch 79: val_loss=1.2992\n",
            "Epoch 80: val_loss=1.2869\n",
            "Epoch 81: val_loss=1.2949\n",
            "Epoch 82: val_loss=1.3502\n",
            "Epoch 83: val_loss=1.3320\n",
            "Epoch 84: val_loss=1.2840\n",
            "Epoch 85: val_loss=1.2893\n",
            "Early stopping triggered.\n",
            "MAE : 0.9128, RMSE: 1.1356, R²: 0.1369\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.9277 ± 0.0198\n",
            "RMSE: 1.1703 ± 0.0333\n",
            "R²  : 0.1221 ± 0.0584\n",
            "\n",
            "=== Финальное обучение на train+val ===\n",
            "Final model saved to final_cnn_model.pth\n",
            "\n",
            "=== Загрузка модели и тестирование ===\n",
            "Test MAE : 0.8015\n",
            "Test RMSE: 1.0344\n",
            "Test R²  : 0.2705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обоснование выбора признаков, модели и параметров\n",
        "\n",
        "В качестве входных признаков используются дескрипторы Mordred, прошедшие стандартизацию через StandardScaler.\n",
        "\n",
        "В качестве модели выбрана одномерная сверточная нейросеть (1D-CNN), способная выявлять локальные зависимости между признаками. Архитектура включает два слоя Conv1d с ReLU, MaxPool1d и AdaptiveMaxPool1d, завершающихся полносвязным выходом. Используется Dropout (0.3–0.4) для регуляризации.\n",
        "\n",
        "Обучение производится с помощью оптимизатора Adam (lr=0.001) и ранней остановки (patience=10) для предотвращения переобучения. Качество модели оценивается по 5-кратной кросс-валидации. После этого модель дообучается на всех обучающих данных и сохраняется для тестирования."
      ],
      "metadata": {
        "id": "OPBVg-BpQ6Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# === Загрузка данных ===\n",
        "df = pd.read_csv('/content/Mordred_nonagg_pca_processed.csv')\n",
        "X = df.drop(columns=['pIC50']).values.astype(np.float32)\n",
        "y = df['pIC50'].values.astype(np.float32)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# === CNN-модель ===\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_len, out_channels=16, kernel_size=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(1, out_channels, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(out_channels, out_channels * 2, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(out_channels * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # -> (batch_size, 1, input_len)\n",
        "        return self.model(x)\n",
        "\n",
        "# === Обучение с ранней остановкой ===\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=10, max_epochs=100):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# === Кросс-валидация ===\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32, shuffle=False)\n",
        "\n",
        "        model = CNN1D(input_len=X_train.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "# === Финальное обучение ===\n",
        "print(\"\\n=== Финальное обучение на train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = CNN1D(input_len=X_trainval.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# === Сохранение модели ===\n",
        "model_path = 'final_cnn_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# === Тестирование ===\n",
        "print(\"\\n=== Загрузка модели и тестирование ===\")\n",
        "loaded_model = CNN1D(input_len=X_trainval.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGxtNOpSHgFp",
        "outputId": "cd4144e2-f560-4f71-ca2c-bd8d3bcb61c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=4.4922\n",
            "Epoch 2: val_loss=2.1715\n",
            "Epoch 3: val_loss=1.5804\n",
            "Epoch 4: val_loss=1.5158\n",
            "Epoch 5: val_loss=1.4812\n",
            "Epoch 6: val_loss=1.4928\n",
            "Epoch 7: val_loss=1.4476\n",
            "Epoch 8: val_loss=1.4119\n",
            "Epoch 9: val_loss=1.4255\n",
            "Epoch 10: val_loss=1.3927\n",
            "Epoch 11: val_loss=1.3717\n",
            "Epoch 12: val_loss=1.3639\n",
            "Epoch 13: val_loss=1.3368\n",
            "Epoch 14: val_loss=1.3515\n",
            "Epoch 15: val_loss=1.3143\n",
            "Epoch 16: val_loss=1.3038\n",
            "Epoch 17: val_loss=1.2869\n",
            "Epoch 18: val_loss=1.2957\n",
            "Epoch 19: val_loss=1.3016\n",
            "Epoch 20: val_loss=1.2761\n",
            "Epoch 21: val_loss=1.3795\n",
            "Epoch 22: val_loss=1.2543\n",
            "Epoch 23: val_loss=1.2510\n",
            "Epoch 24: val_loss=1.2326\n",
            "Epoch 25: val_loss=1.3476\n",
            "Epoch 26: val_loss=1.2281\n",
            "Epoch 27: val_loss=1.2322\n",
            "Epoch 28: val_loss=1.2087\n",
            "Epoch 29: val_loss=1.2043\n",
            "Epoch 30: val_loss=1.1986\n",
            "Epoch 31: val_loss=1.2045\n",
            "Epoch 32: val_loss=1.3002\n",
            "Epoch 33: val_loss=1.1827\n",
            "Epoch 34: val_loss=1.1579\n",
            "Epoch 35: val_loss=1.1551\n",
            "Epoch 36: val_loss=1.4994\n",
            "Epoch 37: val_loss=1.1612\n",
            "Epoch 38: val_loss=1.1957\n",
            "Epoch 39: val_loss=1.1418\n",
            "Epoch 40: val_loss=1.1383\n",
            "Epoch 41: val_loss=1.2427\n",
            "Epoch 42: val_loss=1.1193\n",
            "Epoch 43: val_loss=1.1678\n",
            "Epoch 44: val_loss=1.1322\n",
            "Epoch 45: val_loss=1.1667\n",
            "Epoch 46: val_loss=1.1061\n",
            "Epoch 47: val_loss=1.2418\n",
            "Epoch 48: val_loss=1.0823\n",
            "Epoch 49: val_loss=1.1102\n",
            "Epoch 50: val_loss=1.1147\n",
            "Epoch 51: val_loss=1.1551\n",
            "Epoch 52: val_loss=1.1652\n",
            "Epoch 53: val_loss=1.1032\n",
            "Epoch 54: val_loss=1.1284\n",
            "Epoch 55: val_loss=1.1011\n",
            "Epoch 56: val_loss=1.0526\n",
            "Epoch 57: val_loss=1.0889\n",
            "Epoch 58: val_loss=1.1757\n",
            "Epoch 59: val_loss=1.1003\n",
            "Epoch 60: val_loss=1.2488\n",
            "Epoch 61: val_loss=1.0347\n",
            "Epoch 62: val_loss=1.0461\n",
            "Epoch 63: val_loss=1.0280\n",
            "Epoch 64: val_loss=1.0446\n",
            "Epoch 65: val_loss=1.0633\n",
            "Epoch 66: val_loss=1.0486\n",
            "Epoch 67: val_loss=1.0220\n",
            "Epoch 68: val_loss=1.0288\n",
            "Epoch 69: val_loss=1.0341\n",
            "Epoch 70: val_loss=1.0290\n",
            "Epoch 71: val_loss=1.0165\n",
            "Epoch 72: val_loss=1.1154\n",
            "Epoch 73: val_loss=1.0218\n",
            "Epoch 74: val_loss=1.2053\n",
            "Epoch 75: val_loss=1.0268\n",
            "Epoch 76: val_loss=1.0438\n",
            "Epoch 77: val_loss=1.1542\n",
            "Epoch 78: val_loss=1.0379\n",
            "Epoch 79: val_loss=1.0761\n",
            "Epoch 80: val_loss=1.0156\n",
            "Epoch 81: val_loss=1.0077\n",
            "Epoch 82: val_loss=1.0283\n",
            "Epoch 83: val_loss=1.0161\n",
            "Epoch 84: val_loss=1.0208\n",
            "Epoch 85: val_loss=1.0868\n",
            "Epoch 86: val_loss=1.1463\n",
            "Epoch 87: val_loss=0.9897\n",
            "Epoch 88: val_loss=0.9987\n",
            "Epoch 89: val_loss=1.0097\n",
            "Epoch 90: val_loss=0.9997\n",
            "Epoch 91: val_loss=1.0477\n",
            "Epoch 92: val_loss=0.9944\n",
            "Epoch 93: val_loss=1.0035\n",
            "Epoch 94: val_loss=1.0057\n",
            "Epoch 95: val_loss=1.1265\n",
            "Epoch 96: val_loss=1.0069\n",
            "Epoch 97: val_loss=1.1089\n",
            "Early stopping triggered.\n",
            "MAE : 0.8085, RMSE: 1.0530, R²: 0.2542\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=3.6719\n",
            "Epoch 2: val_loss=2.0235\n",
            "Epoch 3: val_loss=1.8513\n",
            "Epoch 4: val_loss=1.8103\n",
            "Epoch 5: val_loss=1.6392\n",
            "Epoch 6: val_loss=1.6024\n",
            "Epoch 7: val_loss=1.5896\n",
            "Epoch 8: val_loss=1.6910\n",
            "Epoch 9: val_loss=1.5570\n",
            "Epoch 10: val_loss=1.5388\n",
            "Epoch 11: val_loss=1.5308\n",
            "Epoch 12: val_loss=1.5270\n",
            "Epoch 13: val_loss=1.5258\n",
            "Epoch 14: val_loss=1.5177\n",
            "Epoch 15: val_loss=1.5037\n",
            "Epoch 16: val_loss=1.5088\n",
            "Epoch 17: val_loss=1.4851\n",
            "Epoch 18: val_loss=1.5039\n",
            "Epoch 19: val_loss=1.6227\n",
            "Epoch 20: val_loss=1.4501\n",
            "Epoch 21: val_loss=1.4562\n",
            "Epoch 22: val_loss=1.4435\n",
            "Epoch 23: val_loss=1.5179\n",
            "Epoch 24: val_loss=1.5098\n",
            "Epoch 25: val_loss=1.3905\n",
            "Epoch 26: val_loss=1.3747\n",
            "Epoch 27: val_loss=1.3720\n",
            "Epoch 28: val_loss=1.3498\n",
            "Epoch 29: val_loss=1.3492\n",
            "Epoch 30: val_loss=1.4515\n",
            "Epoch 31: val_loss=1.3860\n",
            "Epoch 32: val_loss=1.4046\n",
            "Epoch 33: val_loss=1.3896\n",
            "Epoch 34: val_loss=1.4652\n",
            "Epoch 35: val_loss=1.2840\n",
            "Epoch 36: val_loss=1.3126\n",
            "Epoch 37: val_loss=1.4550\n",
            "Epoch 38: val_loss=1.7023\n",
            "Epoch 39: val_loss=1.3579\n",
            "Epoch 40: val_loss=1.2603\n",
            "Epoch 41: val_loss=1.2543\n",
            "Epoch 42: val_loss=1.2467\n",
            "Epoch 43: val_loss=1.2891\n",
            "Epoch 44: val_loss=1.2191\n",
            "Epoch 45: val_loss=1.3673\n",
            "Epoch 46: val_loss=1.2969\n",
            "Epoch 47: val_loss=1.2360\n",
            "Epoch 48: val_loss=1.3002\n",
            "Epoch 49: val_loss=1.1794\n",
            "Epoch 50: val_loss=1.2390\n",
            "Epoch 51: val_loss=1.1775\n",
            "Epoch 52: val_loss=1.1957\n",
            "Epoch 53: val_loss=1.2288\n",
            "Epoch 54: val_loss=1.2573\n",
            "Epoch 55: val_loss=1.1816\n",
            "Epoch 56: val_loss=1.1885\n",
            "Epoch 57: val_loss=1.2939\n",
            "Epoch 58: val_loss=1.1408\n",
            "Epoch 59: val_loss=1.1728\n",
            "Epoch 60: val_loss=1.4248\n",
            "Epoch 61: val_loss=1.2162\n",
            "Epoch 62: val_loss=1.1380\n",
            "Epoch 63: val_loss=1.1297\n",
            "Epoch 64: val_loss=1.1931\n",
            "Epoch 65: val_loss=1.3676\n",
            "Epoch 66: val_loss=1.1366\n",
            "Epoch 67: val_loss=1.2254\n",
            "Epoch 68: val_loss=1.1221\n",
            "Epoch 69: val_loss=1.1367\n",
            "Epoch 70: val_loss=1.1481\n",
            "Epoch 71: val_loss=1.1449\n",
            "Epoch 72: val_loss=1.1474\n",
            "Epoch 73: val_loss=1.1161\n",
            "Epoch 74: val_loss=1.1621\n",
            "Epoch 75: val_loss=1.1345\n",
            "Epoch 76: val_loss=1.1641\n",
            "Epoch 77: val_loss=1.1125\n",
            "Epoch 78: val_loss=1.1508\n",
            "Epoch 79: val_loss=1.1672\n",
            "Epoch 80: val_loss=1.2088\n",
            "Epoch 81: val_loss=1.1242\n",
            "Epoch 82: val_loss=1.1257\n",
            "Epoch 83: val_loss=1.1192\n",
            "Epoch 84: val_loss=1.1489\n",
            "Epoch 85: val_loss=1.1197\n",
            "Epoch 86: val_loss=1.0969\n",
            "Epoch 87: val_loss=1.1485\n",
            "Epoch 88: val_loss=1.1216\n",
            "Epoch 89: val_loss=1.2375\n",
            "Epoch 90: val_loss=1.1366\n",
            "Epoch 91: val_loss=1.1435\n",
            "Epoch 92: val_loss=1.2105\n",
            "Epoch 93: val_loss=1.1018\n",
            "Epoch 94: val_loss=1.2490\n",
            "Epoch 95: val_loss=1.1033\n",
            "Epoch 96: val_loss=1.0983\n",
            "Early stopping triggered.\n",
            "MAE : 0.8032, RMSE: 1.0480, R²: 0.3306\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=6.3224\n",
            "Epoch 2: val_loss=2.5865\n",
            "Epoch 3: val_loss=1.7434\n",
            "Epoch 4: val_loss=1.6693\n",
            "Epoch 5: val_loss=1.6093\n",
            "Epoch 6: val_loss=1.5845\n",
            "Epoch 7: val_loss=1.5783\n",
            "Epoch 8: val_loss=1.6780\n",
            "Epoch 9: val_loss=1.5392\n",
            "Epoch 10: val_loss=1.5312\n",
            "Epoch 11: val_loss=1.5024\n",
            "Epoch 12: val_loss=1.5060\n",
            "Epoch 13: val_loss=1.5399\n",
            "Epoch 14: val_loss=1.4886\n",
            "Epoch 15: val_loss=1.4627\n",
            "Epoch 16: val_loss=1.4471\n",
            "Epoch 17: val_loss=1.4891\n",
            "Epoch 18: val_loss=1.4684\n",
            "Epoch 19: val_loss=1.4210\n",
            "Epoch 20: val_loss=1.4102\n",
            "Epoch 21: val_loss=1.4150\n",
            "Epoch 22: val_loss=1.3671\n",
            "Epoch 23: val_loss=1.4148\n",
            "Epoch 24: val_loss=1.3661\n",
            "Epoch 25: val_loss=1.3420\n",
            "Epoch 26: val_loss=1.3501\n",
            "Epoch 27: val_loss=1.3646\n",
            "Epoch 28: val_loss=1.4241\n",
            "Epoch 29: val_loss=1.3175\n",
            "Epoch 30: val_loss=1.2774\n",
            "Epoch 31: val_loss=1.2828\n",
            "Epoch 32: val_loss=1.2606\n",
            "Epoch 33: val_loss=1.2990\n",
            "Epoch 34: val_loss=1.3300\n",
            "Epoch 35: val_loss=1.3394\n",
            "Epoch 36: val_loss=1.2634\n",
            "Epoch 37: val_loss=1.2090\n",
            "Epoch 38: val_loss=1.2600\n",
            "Epoch 39: val_loss=1.3150\n",
            "Epoch 40: val_loss=1.5282\n",
            "Epoch 41: val_loss=1.2175\n",
            "Epoch 42: val_loss=1.2422\n",
            "Epoch 43: val_loss=1.2870\n",
            "Epoch 44: val_loss=1.2193\n",
            "Epoch 45: val_loss=1.2111\n",
            "Epoch 46: val_loss=1.1952\n",
            "Epoch 47: val_loss=1.1943\n",
            "Epoch 48: val_loss=1.1690\n",
            "Epoch 49: val_loss=1.2374\n",
            "Epoch 50: val_loss=1.1647\n",
            "Epoch 51: val_loss=1.1758\n",
            "Epoch 52: val_loss=1.1755\n",
            "Epoch 53: val_loss=1.2930\n",
            "Epoch 54: val_loss=1.1749\n",
            "Epoch 55: val_loss=1.2396\n",
            "Epoch 56: val_loss=1.1785\n",
            "Epoch 57: val_loss=1.1628\n",
            "Epoch 58: val_loss=1.7505\n",
            "Epoch 59: val_loss=1.1698\n",
            "Epoch 60: val_loss=1.1933\n",
            "Epoch 61: val_loss=1.2159\n",
            "Epoch 62: val_loss=1.1942\n",
            "Epoch 63: val_loss=1.2284\n",
            "Epoch 64: val_loss=1.1347\n",
            "Epoch 65: val_loss=1.2194\n",
            "Epoch 66: val_loss=1.2544\n",
            "Epoch 67: val_loss=1.0939\n",
            "Epoch 68: val_loss=1.2834\n",
            "Epoch 69: val_loss=1.1255\n",
            "Epoch 70: val_loss=1.1062\n",
            "Epoch 71: val_loss=1.1173\n",
            "Epoch 72: val_loss=1.4296\n",
            "Epoch 73: val_loss=1.1554\n",
            "Epoch 74: val_loss=1.1432\n",
            "Epoch 75: val_loss=1.1560\n",
            "Epoch 76: val_loss=1.1267\n",
            "Epoch 77: val_loss=1.2279\n",
            "Early stopping triggered.\n",
            "MAE : 0.8783, RMSE: 1.1080, R²: 0.2387\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=12.5524\n",
            "Epoch 2: val_loss=3.8240\n",
            "Epoch 3: val_loss=1.9025\n",
            "Epoch 4: val_loss=1.6816\n",
            "Epoch 5: val_loss=1.6061\n",
            "Epoch 6: val_loss=1.6178\n",
            "Epoch 7: val_loss=1.5819\n",
            "Epoch 8: val_loss=1.5615\n",
            "Epoch 9: val_loss=1.5595\n",
            "Epoch 10: val_loss=1.5667\n",
            "Epoch 11: val_loss=1.5078\n",
            "Epoch 12: val_loss=1.6333\n",
            "Epoch 13: val_loss=1.6079\n",
            "Epoch 14: val_loss=1.6268\n",
            "Epoch 15: val_loss=1.6103\n",
            "Epoch 16: val_loss=1.5304\n",
            "Epoch 17: val_loss=1.5358\n",
            "Epoch 18: val_loss=1.4540\n",
            "Epoch 19: val_loss=1.5701\n",
            "Epoch 20: val_loss=1.4240\n",
            "Epoch 21: val_loss=1.4674\n",
            "Epoch 22: val_loss=1.5851\n",
            "Epoch 23: val_loss=1.5765\n",
            "Epoch 24: val_loss=1.4137\n",
            "Epoch 25: val_loss=1.4995\n",
            "Epoch 26: val_loss=1.6545\n",
            "Epoch 27: val_loss=1.4462\n",
            "Epoch 28: val_loss=1.6303\n",
            "Epoch 29: val_loss=1.4427\n",
            "Epoch 30: val_loss=1.3287\n",
            "Epoch 31: val_loss=1.6172\n",
            "Epoch 32: val_loss=1.3123\n",
            "Epoch 33: val_loss=1.5130\n",
            "Epoch 34: val_loss=1.5001\n",
            "Epoch 35: val_loss=1.4003\n",
            "Epoch 36: val_loss=1.4230\n",
            "Epoch 37: val_loss=1.4907\n",
            "Epoch 38: val_loss=1.6951\n",
            "Epoch 39: val_loss=1.4204\n",
            "Epoch 40: val_loss=1.5541\n",
            "Epoch 41: val_loss=1.3541\n",
            "Epoch 42: val_loss=1.3368\n",
            "Early stopping triggered.\n",
            "MAE : 0.8836, RMSE: 1.1564, R²: 0.1554\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=6.4666\n",
            "Epoch 2: val_loss=2.3122\n",
            "Epoch 3: val_loss=1.9505\n",
            "Epoch 4: val_loss=1.6174\n",
            "Epoch 5: val_loss=1.7415\n",
            "Epoch 6: val_loss=1.5023\n",
            "Epoch 7: val_loss=1.5014\n",
            "Epoch 8: val_loss=1.5991\n",
            "Epoch 9: val_loss=1.4795\n",
            "Epoch 10: val_loss=1.4569\n",
            "Epoch 11: val_loss=1.5344\n",
            "Epoch 12: val_loss=1.4450\n",
            "Epoch 13: val_loss=1.4406\n",
            "Epoch 14: val_loss=1.4114\n",
            "Epoch 15: val_loss=1.4041\n",
            "Epoch 16: val_loss=1.4344\n",
            "Epoch 17: val_loss=1.3954\n",
            "Epoch 18: val_loss=1.3646\n",
            "Epoch 19: val_loss=1.4552\n",
            "Epoch 20: val_loss=1.3561\n",
            "Epoch 21: val_loss=1.3623\n",
            "Epoch 22: val_loss=1.3309\n",
            "Epoch 23: val_loss=1.3410\n",
            "Epoch 24: val_loss=1.4121\n",
            "Epoch 25: val_loss=1.3051\n",
            "Epoch 26: val_loss=1.3340\n",
            "Epoch 27: val_loss=1.3880\n",
            "Epoch 28: val_loss=1.3356\n",
            "Epoch 29: val_loss=1.2694\n",
            "Epoch 30: val_loss=1.2595\n",
            "Epoch 31: val_loss=1.2916\n",
            "Epoch 32: val_loss=1.2423\n",
            "Epoch 33: val_loss=1.2590\n",
            "Epoch 34: val_loss=1.2419\n",
            "Epoch 35: val_loss=1.2645\n",
            "Epoch 36: val_loss=1.2686\n",
            "Epoch 37: val_loss=1.2246\n",
            "Epoch 38: val_loss=1.2166\n",
            "Epoch 39: val_loss=1.2021\n",
            "Epoch 40: val_loss=1.2903\n",
            "Epoch 41: val_loss=1.2009\n",
            "Epoch 42: val_loss=1.3422\n",
            "Epoch 43: val_loss=1.2106\n",
            "Epoch 44: val_loss=1.2001\n",
            "Epoch 45: val_loss=1.1871\n",
            "Epoch 46: val_loss=1.4141\n",
            "Epoch 47: val_loss=1.2824\n",
            "Epoch 48: val_loss=1.1958\n",
            "Epoch 49: val_loss=1.1913\n",
            "Epoch 50: val_loss=1.1973\n",
            "Epoch 51: val_loss=1.1710\n",
            "Epoch 52: val_loss=1.1758\n",
            "Epoch 53: val_loss=1.2732\n",
            "Epoch 54: val_loss=1.2815\n",
            "Epoch 55: val_loss=1.2028\n",
            "Epoch 56: val_loss=1.2492\n",
            "Epoch 57: val_loss=1.3668\n",
            "Epoch 58: val_loss=1.1922\n",
            "Epoch 59: val_loss=1.2221\n",
            "Epoch 60: val_loss=1.2227\n",
            "Epoch 61: val_loss=1.1900\n",
            "Early stopping triggered.\n",
            "MAE : 0.8461, RMSE: 1.0912, R²: 0.2031\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.8439 ± 0.0337\n",
            "RMSE: 1.0913 ± 0.0396\n",
            "R²  : 0.2364 ± 0.0581\n",
            "\n",
            "=== Финальное обучение на train+val ===\n",
            "Final model saved to final_cnn_model.pth\n",
            "\n",
            "=== Загрузка модели и тестирование ===\n",
            "Test MAE : 0.7389\n",
            "Test RMSE: 0.9464\n",
            "Test R²  : 0.3893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее датасет RDKit с теми же параметрами"
      ],
      "metadata": {
        "id": "JeO2-QgCQ_O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# === Загрузка данных ===\n",
        "df = pd.read_csv('/content/RDKit_nonagg_pca_processed.csv')\n",
        "X = df.drop(columns=['pIC50']).values.astype(np.float32)\n",
        "y = df['pIC50'].values.astype(np.float32)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X,\n",
        "                                                          y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# === CNN-модель ===\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_len, out_channels=16, kernel_size=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(1, out_channels, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(out_channels, out_channels * 2, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(out_channels * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # -> (batch_size, 1, input_len)\n",
        "        return self.model(x)\n",
        "\n",
        "# === Обучение с ранней остановкой ===\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=10, max_epochs=100):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# === Кросс-валидация ===\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32, shuffle=False)\n",
        "\n",
        "        model = CNN1D(input_len=X_train.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "# === Финальное обучение ===\n",
        "print(\"\\n=== Финальное обучение на train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = CNN1D(input_len=X_trainval.shape[1], out_channels=32, kernel_size=5, dropout=0.2).to(device)\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# === Сохранение модели ===\n",
        "model_path = 'final_cnn_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# === Тестирование ===\n",
        "print(\"\\n=== Загрузка модели и тестирование ===\")\n",
        "loaded_model = CNN1D(input_len=X_trainval.shape[1], out_channels=32, kernel_size=5, dropout=0.2).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhBC-X7PHs3Q",
        "outputId": "d25669e5-7a1d-4c80-ef92-64db94650e6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=3.2672\n",
            "Epoch 2: val_loss=1.5712\n",
            "Epoch 3: val_loss=1.5016\n",
            "Epoch 4: val_loss=1.4701\n",
            "Epoch 5: val_loss=1.4478\n",
            "Epoch 6: val_loss=1.4318\n",
            "Epoch 7: val_loss=1.4745\n",
            "Epoch 8: val_loss=1.4323\n",
            "Epoch 9: val_loss=1.3720\n",
            "Epoch 10: val_loss=1.5644\n",
            "Epoch 11: val_loss=1.3916\n",
            "Epoch 12: val_loss=1.4103\n",
            "Epoch 13: val_loss=1.3140\n",
            "Epoch 14: val_loss=1.4867\n",
            "Epoch 15: val_loss=1.3193\n",
            "Epoch 16: val_loss=1.3992\n",
            "Epoch 17: val_loss=1.2943\n",
            "Epoch 18: val_loss=1.3112\n",
            "Epoch 19: val_loss=1.3624\n",
            "Epoch 20: val_loss=1.5252\n",
            "Epoch 21: val_loss=1.2585\n",
            "Epoch 22: val_loss=1.3295\n",
            "Epoch 23: val_loss=1.2585\n",
            "Epoch 24: val_loss=1.4233\n",
            "Epoch 25: val_loss=1.3383\n",
            "Epoch 26: val_loss=1.2473\n",
            "Epoch 27: val_loss=1.2923\n",
            "Epoch 28: val_loss=1.2715\n",
            "Epoch 29: val_loss=1.2662\n",
            "Epoch 30: val_loss=1.3426\n",
            "Epoch 31: val_loss=1.2039\n",
            "Epoch 32: val_loss=1.3016\n",
            "Epoch 33: val_loss=1.3323\n",
            "Epoch 34: val_loss=1.3212\n",
            "Epoch 35: val_loss=1.2599\n",
            "Epoch 36: val_loss=1.3192\n",
            "Epoch 37: val_loss=1.3246\n",
            "Epoch 38: val_loss=1.2844\n",
            "Epoch 39: val_loss=1.2173\n",
            "Epoch 40: val_loss=1.2556\n",
            "Epoch 41: val_loss=1.2740\n",
            "Early stopping triggered.\n",
            "MAE : 0.8271, RMSE: 1.1273, R²: 0.1743\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=2.1724\n",
            "Epoch 2: val_loss=1.4150\n",
            "Epoch 3: val_loss=1.3574\n",
            "Epoch 4: val_loss=1.3809\n",
            "Epoch 5: val_loss=1.3209\n",
            "Epoch 6: val_loss=1.3768\n",
            "Epoch 7: val_loss=1.3746\n",
            "Epoch 8: val_loss=1.3161\n",
            "Epoch 9: val_loss=1.2570\n",
            "Epoch 10: val_loss=1.2785\n",
            "Epoch 11: val_loss=1.2579\n",
            "Epoch 12: val_loss=1.2028\n",
            "Epoch 13: val_loss=1.2277\n",
            "Epoch 14: val_loss=1.2106\n",
            "Epoch 15: val_loss=1.1810\n",
            "Epoch 16: val_loss=1.2998\n",
            "Epoch 17: val_loss=1.1689\n",
            "Epoch 18: val_loss=1.2243\n",
            "Epoch 19: val_loss=1.6398\n",
            "Epoch 20: val_loss=1.1163\n",
            "Epoch 21: val_loss=1.2519\n",
            "Epoch 22: val_loss=1.1557\n",
            "Epoch 23: val_loss=1.1348\n",
            "Epoch 24: val_loss=1.1455\n",
            "Epoch 25: val_loss=1.0871\n",
            "Epoch 26: val_loss=1.1458\n",
            "Epoch 27: val_loss=1.0905\n",
            "Epoch 28: val_loss=1.1871\n",
            "Epoch 29: val_loss=1.2744\n",
            "Epoch 30: val_loss=1.0390\n",
            "Epoch 31: val_loss=1.0538\n",
            "Epoch 32: val_loss=1.2298\n",
            "Epoch 33: val_loss=1.0959\n",
            "Epoch 34: val_loss=1.2196\n",
            "Epoch 35: val_loss=1.1507\n",
            "Epoch 36: val_loss=1.0638\n",
            "Epoch 37: val_loss=1.0559\n",
            "Epoch 38: val_loss=1.0472\n",
            "Epoch 39: val_loss=1.1230\n",
            "Epoch 40: val_loss=1.0262\n",
            "Epoch 41: val_loss=1.0227\n",
            "Epoch 42: val_loss=1.0811\n",
            "Epoch 43: val_loss=1.1618\n",
            "Epoch 44: val_loss=1.0112\n",
            "Epoch 45: val_loss=1.1096\n",
            "Epoch 46: val_loss=1.0480\n",
            "Epoch 47: val_loss=1.0782\n",
            "Epoch 48: val_loss=1.1048\n",
            "Epoch 49: val_loss=0.9928\n",
            "Epoch 50: val_loss=1.0101\n",
            "Epoch 51: val_loss=1.1166\n",
            "Epoch 52: val_loss=0.9719\n",
            "Epoch 53: val_loss=1.0930\n",
            "Epoch 54: val_loss=1.1188\n",
            "Epoch 55: val_loss=1.0248\n",
            "Epoch 56: val_loss=1.0315\n",
            "Epoch 57: val_loss=1.1920\n",
            "Epoch 58: val_loss=0.9870\n",
            "Epoch 59: val_loss=1.1297\n",
            "Epoch 60: val_loss=0.9907\n",
            "Epoch 61: val_loss=1.0174\n",
            "Epoch 62: val_loss=1.1241\n",
            "Early stopping triggered.\n",
            "MAE : 0.8240, RMSE: 1.0590, R²: 0.2066\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=2.2292\n",
            "Epoch 2: val_loss=1.4954\n",
            "Epoch 3: val_loss=1.4556\n",
            "Epoch 4: val_loss=1.4305\n",
            "Epoch 5: val_loss=1.4045\n",
            "Epoch 6: val_loss=1.4750\n",
            "Epoch 7: val_loss=1.3717\n",
            "Epoch 8: val_loss=1.3580\n",
            "Epoch 9: val_loss=1.3335\n",
            "Epoch 10: val_loss=1.4594\n",
            "Epoch 11: val_loss=1.3327\n",
            "Epoch 12: val_loss=1.2791\n",
            "Epoch 13: val_loss=1.3332\n",
            "Epoch 14: val_loss=1.3346\n",
            "Epoch 15: val_loss=1.2598\n",
            "Epoch 16: val_loss=1.2389\n",
            "Epoch 17: val_loss=1.2081\n",
            "Epoch 18: val_loss=1.2243\n",
            "Epoch 19: val_loss=1.1850\n",
            "Epoch 20: val_loss=1.2332\n",
            "Epoch 21: val_loss=1.2719\n",
            "Epoch 22: val_loss=1.3672\n",
            "Epoch 23: val_loss=1.2111\n",
            "Epoch 24: val_loss=1.1295\n",
            "Epoch 25: val_loss=1.2549\n",
            "Epoch 26: val_loss=1.1570\n",
            "Epoch 27: val_loss=1.1240\n",
            "Epoch 28: val_loss=1.4300\n",
            "Epoch 29: val_loss=1.1175\n",
            "Epoch 30: val_loss=1.1213\n",
            "Epoch 31: val_loss=1.3170\n",
            "Epoch 32: val_loss=1.3647\n",
            "Epoch 33: val_loss=1.1127\n",
            "Epoch 34: val_loss=1.0980\n",
            "Epoch 35: val_loss=1.1119\n",
            "Epoch 36: val_loss=1.0916\n",
            "Epoch 37: val_loss=1.1133\n",
            "Epoch 38: val_loss=1.1445\n",
            "Epoch 39: val_loss=1.1196\n",
            "Epoch 40: val_loss=1.2792\n",
            "Epoch 41: val_loss=1.1384\n",
            "Epoch 42: val_loss=1.1013\n",
            "Epoch 43: val_loss=1.5543\n",
            "Epoch 44: val_loss=1.1302\n",
            "Epoch 45: val_loss=1.0751\n",
            "Epoch 46: val_loss=1.0742\n",
            "Epoch 47: val_loss=1.1334\n",
            "Epoch 48: val_loss=1.0806\n",
            "Epoch 49: val_loss=1.1040\n",
            "Epoch 50: val_loss=1.0834\n",
            "Epoch 51: val_loss=1.0655\n",
            "Epoch 52: val_loss=1.0467\n",
            "Epoch 53: val_loss=1.0829\n",
            "Epoch 54: val_loss=1.0599\n",
            "Epoch 55: val_loss=1.0492\n",
            "Epoch 56: val_loss=1.0603\n",
            "Epoch 57: val_loss=1.1334\n",
            "Epoch 58: val_loss=1.0613\n",
            "Epoch 59: val_loss=1.1680\n",
            "Epoch 60: val_loss=1.0547\n",
            "Epoch 61: val_loss=1.2047\n",
            "Epoch 62: val_loss=1.1123\n",
            "Early stopping triggered.\n",
            "MAE : 0.8099, RMSE: 1.0613, R²: 0.2831\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=2.8453\n",
            "Epoch 2: val_loss=1.5675\n",
            "Epoch 3: val_loss=1.5072\n",
            "Epoch 4: val_loss=1.4780\n",
            "Epoch 5: val_loss=1.5559\n",
            "Epoch 6: val_loss=1.4313\n",
            "Epoch 7: val_loss=1.4137\n",
            "Epoch 8: val_loss=1.4361\n",
            "Epoch 9: val_loss=1.4353\n",
            "Epoch 10: val_loss=1.3244\n",
            "Epoch 11: val_loss=1.3287\n",
            "Epoch 12: val_loss=1.2732\n",
            "Epoch 13: val_loss=1.2735\n",
            "Epoch 14: val_loss=1.3145\n",
            "Epoch 15: val_loss=1.3190\n",
            "Epoch 16: val_loss=1.2310\n",
            "Epoch 17: val_loss=1.2275\n",
            "Epoch 18: val_loss=1.1955\n",
            "Epoch 19: val_loss=1.2879\n",
            "Epoch 20: val_loss=1.2366\n",
            "Epoch 21: val_loss=1.5612\n",
            "Epoch 22: val_loss=1.2617\n",
            "Epoch 23: val_loss=1.1629\n",
            "Epoch 24: val_loss=1.2069\n",
            "Epoch 25: val_loss=1.1539\n",
            "Epoch 26: val_loss=1.1648\n",
            "Epoch 27: val_loss=1.2509\n",
            "Epoch 28: val_loss=1.1445\n",
            "Epoch 29: val_loss=1.3596\n",
            "Epoch 30: val_loss=1.1365\n",
            "Epoch 31: val_loss=1.1460\n",
            "Epoch 32: val_loss=1.1296\n",
            "Epoch 33: val_loss=1.1525\n",
            "Epoch 34: val_loss=1.1523\n",
            "Epoch 35: val_loss=1.2921\n",
            "Epoch 36: val_loss=1.1866\n",
            "Epoch 37: val_loss=1.1122\n",
            "Epoch 38: val_loss=1.1019\n",
            "Epoch 39: val_loss=1.4006\n",
            "Epoch 40: val_loss=1.1504\n",
            "Epoch 41: val_loss=1.1563\n",
            "Epoch 42: val_loss=1.1693\n",
            "Epoch 43: val_loss=1.1059\n",
            "Epoch 44: val_loss=1.1835\n",
            "Epoch 45: val_loss=1.1238\n",
            "Epoch 46: val_loss=1.1163\n",
            "Epoch 47: val_loss=1.1178\n",
            "Epoch 48: val_loss=1.3952\n",
            "Early stopping triggered.\n",
            "MAE : 0.9511, RMSE: 1.1806, R²: 0.1349\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=4.6413\n",
            "Epoch 2: val_loss=1.6434\n",
            "Epoch 3: val_loss=1.5216\n",
            "Epoch 4: val_loss=1.4813\n",
            "Epoch 5: val_loss=1.5092\n",
            "Epoch 6: val_loss=1.4878\n",
            "Epoch 7: val_loss=1.4428\n",
            "Epoch 8: val_loss=1.4717\n",
            "Epoch 9: val_loss=1.4556\n",
            "Epoch 10: val_loss=1.4908\n",
            "Epoch 11: val_loss=1.3921\n",
            "Epoch 12: val_loss=1.3695\n",
            "Epoch 13: val_loss=1.3498\n",
            "Epoch 14: val_loss=1.3547\n",
            "Epoch 15: val_loss=1.3628\n",
            "Epoch 16: val_loss=1.3553\n",
            "Epoch 17: val_loss=1.3280\n",
            "Epoch 18: val_loss=1.3027\n",
            "Epoch 19: val_loss=1.3129\n",
            "Epoch 20: val_loss=1.3521\n",
            "Epoch 21: val_loss=1.3944\n",
            "Epoch 22: val_loss=1.2607\n",
            "Epoch 23: val_loss=1.3307\n",
            "Epoch 24: val_loss=1.2443\n",
            "Epoch 25: val_loss=1.3019\n",
            "Epoch 26: val_loss=1.5678\n",
            "Epoch 27: val_loss=1.2805\n",
            "Epoch 28: val_loss=1.2631\n",
            "Epoch 29: val_loss=1.2562\n",
            "Epoch 30: val_loss=1.2573\n",
            "Epoch 31: val_loss=1.3478\n",
            "Epoch 32: val_loss=1.1956\n",
            "Epoch 33: val_loss=1.2627\n",
            "Epoch 34: val_loss=1.3624\n",
            "Epoch 35: val_loss=1.2235\n",
            "Epoch 36: val_loss=1.2498\n",
            "Epoch 37: val_loss=1.2428\n",
            "Epoch 38: val_loss=1.2638\n",
            "Epoch 39: val_loss=1.2990\n",
            "Epoch 40: val_loss=1.2031\n",
            "Epoch 41: val_loss=1.2710\n",
            "Epoch 42: val_loss=1.2710\n",
            "Early stopping triggered.\n",
            "MAE : 0.8397, RMSE: 1.0975, R²: 0.2266\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.8504 ± 0.0512\n",
            "RMSE: 1.1051 ± 0.0454\n",
            "R²  : 0.2051 ± 0.0498\n",
            "\n",
            "=== Финальное обучение на train+val ===\n",
            "Final model saved to final_cnn_model.pth\n",
            "\n",
            "=== Загрузка модели и тестирование ===\n",
            "Test MAE : 0.7857\n",
            "Test RMSE: 1.0213\n",
            "Test R²  : 0.3465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# === Загрузка данных ===\n",
        "df = pd.read_csv('/content/RDKit_nonagg_pca_processed.csv')\n",
        "X = df.drop(columns=['pIC50']).values.astype(np.float32)\n",
        "y = df['pIC50'].values.astype(np.float32)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# === CNN-модель ===\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_len, out_channels=16, kernel_size=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(1, out_channels, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(out_channels, out_channels * 2, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(out_channels * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # -> (batch_size, 1, input_len)\n",
        "        return self.model(x)\n",
        "\n",
        "# === Обучение с ранней остановкой ===\n",
        "def train_with_early_stopping(model, train_loader, val_loader=None, patience=10, max_epochs=100):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    pred = model(xb)\n",
        "                    loss = criterion(pred, yb)\n",
        "                    val_losses.append(loss.item())\n",
        "            val_loss = np.mean(val_losses)\n",
        "            print(f\"Epoch {epoch+1}: val_loss={val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_model_wts = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "        else:\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    if best_model_wts:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# === Кросс-валидация ===\n",
        "def train_model(X_trainval, y_trainval):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    mae_scores, rmse_scores, r2_scores = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "        X_train, X_val = X_trainval[train_idx], X_trainval[val_idx]\n",
        "        y_train, y_val = y_trainval[train_idx], y_trainval[val_idx]\n",
        "\n",
        "        X_train_t = torch.from_numpy(X_train).float()\n",
        "        y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
        "        X_val_t = torch.from_numpy(X_val).float()\n",
        "        y_val_t = torch.from_numpy(y_val).float().unsqueeze(1)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
        "        val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32, shuffle=False)\n",
        "\n",
        "        model = CNN1D(input_len=X_train.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "\n",
        "        model = train_with_early_stopping(model, train_loader, val_loader)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_val_t.to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_val, preds)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "        r2 = r2_score(y_val, preds)\n",
        "        print(f\"MAE : {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return mae_scores, rmse_scores, r2_scores\n",
        "\n",
        "mae_scores, rmse_scores, r2_scores = train_model(X_trainval, y_trainval)\n",
        "\n",
        "print(\"\\n=== Метрики на кросс-валидации ===\")\n",
        "print(f\"MAE : {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n",
        "print(f\"RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
        "print(f\"R²  : {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
        "\n",
        "# === Финальное обучение ===\n",
        "print(\"\\n=== Финальное обучение на train+val ===\")\n",
        "X_trainval_t = torch.from_numpy(X_trainval).float()\n",
        "y_trainval_t = torch.from_numpy(y_trainval).float().unsqueeze(1)\n",
        "trainval_loader = DataLoader(TensorDataset(X_trainval_t, y_trainval_t), batch_size=32, shuffle=True)\n",
        "\n",
        "final_model = CNN1D(input_len=X_trainval.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "final_model = train_with_early_stopping(final_model, trainval_loader, val_loader=None)\n",
        "\n",
        "# === Сохранение модели ===\n",
        "model_path = 'final_cnn_model.pth'\n",
        "torch.save(final_model.state_dict(), model_path)\n",
        "print(f\"Final model saved to {model_path}\")\n",
        "\n",
        "# === Тестирование ===\n",
        "print(\"\\n=== Загрузка модели и тестирование ===\")\n",
        "loaded_model = CNN1D(input_len=X_trainval.shape[1], out_channels=64, kernel_size=7, dropout=0.4).to(device)\n",
        "\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "X_test_t = torch.from_numpy(X_test).float().to(device)\n",
        "with torch.no_grad():\n",
        "    y_test_pred = loaded_model(X_test_t).squeeze().cpu().numpy()\n",
        "\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "print(f\"Test R²  : {r2_score(y_test, y_test_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG2UfFUNH4Rq",
        "outputId": "bc54cc1d-613e-48f8-d5a9-34cd5e987837"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1: val_loss=3.2672\n",
            "Epoch 2: val_loss=1.5712\n",
            "Epoch 3: val_loss=1.5016\n",
            "Epoch 4: val_loss=1.4702\n",
            "Epoch 5: val_loss=1.4462\n",
            "Epoch 6: val_loss=1.4273\n",
            "Epoch 7: val_loss=1.4771\n",
            "Epoch 8: val_loss=1.4316\n",
            "Epoch 9: val_loss=1.3728\n",
            "Epoch 10: val_loss=1.5801\n",
            "Epoch 11: val_loss=1.3940\n",
            "Epoch 12: val_loss=1.4072\n",
            "Epoch 13: val_loss=1.3207\n",
            "Epoch 14: val_loss=1.4998\n",
            "Epoch 15: val_loss=1.3189\n",
            "Epoch 16: val_loss=1.3919\n",
            "Epoch 17: val_loss=1.3000\n",
            "Epoch 18: val_loss=1.3078\n",
            "Epoch 19: val_loss=1.4292\n",
            "Epoch 20: val_loss=1.4716\n",
            "Epoch 21: val_loss=1.2580\n",
            "Epoch 22: val_loss=1.3122\n",
            "Epoch 23: val_loss=1.2307\n",
            "Epoch 24: val_loss=1.4294\n",
            "Epoch 25: val_loss=1.3153\n",
            "Epoch 26: val_loss=1.2327\n",
            "Epoch 27: val_loss=1.3025\n",
            "Epoch 28: val_loss=1.2406\n",
            "Epoch 29: val_loss=1.2403\n",
            "Epoch 30: val_loss=1.2687\n",
            "Epoch 31: val_loss=1.1770\n",
            "Epoch 32: val_loss=1.2590\n",
            "Epoch 33: val_loss=1.2950\n",
            "Epoch 34: val_loss=1.3366\n",
            "Epoch 35: val_loss=1.1841\n",
            "Epoch 36: val_loss=1.2436\n",
            "Epoch 37: val_loss=1.2788\n",
            "Epoch 38: val_loss=1.2268\n",
            "Epoch 39: val_loss=1.1858\n",
            "Epoch 40: val_loss=1.2700\n",
            "Epoch 41: val_loss=1.3288\n",
            "Early stopping triggered.\n",
            "MAE : 0.8402, RMSE: 1.1544, R²: 0.1342\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1: val_loss=2.1724\n",
            "Epoch 2: val_loss=1.4150\n",
            "Epoch 3: val_loss=1.3571\n",
            "Epoch 4: val_loss=1.3815\n",
            "Epoch 5: val_loss=1.3218\n",
            "Epoch 6: val_loss=1.3725\n",
            "Epoch 7: val_loss=1.3807\n",
            "Epoch 8: val_loss=1.3162\n",
            "Epoch 9: val_loss=1.2529\n",
            "Epoch 10: val_loss=1.2721\n",
            "Epoch 11: val_loss=1.2565\n",
            "Epoch 12: val_loss=1.2021\n",
            "Epoch 13: val_loss=1.2434\n",
            "Epoch 14: val_loss=1.2369\n",
            "Epoch 15: val_loss=1.1895\n",
            "Epoch 16: val_loss=1.2798\n",
            "Epoch 17: val_loss=1.1589\n",
            "Epoch 18: val_loss=1.2055\n",
            "Epoch 19: val_loss=1.5810\n",
            "Epoch 20: val_loss=1.1099\n",
            "Epoch 21: val_loss=1.2513\n",
            "Epoch 22: val_loss=1.1424\n",
            "Epoch 23: val_loss=1.1083\n",
            "Epoch 24: val_loss=1.1422\n",
            "Epoch 25: val_loss=1.0771\n",
            "Epoch 26: val_loss=1.1453\n",
            "Epoch 27: val_loss=1.0613\n",
            "Epoch 28: val_loss=1.2377\n",
            "Epoch 29: val_loss=1.2782\n",
            "Epoch 30: val_loss=1.0428\n",
            "Epoch 31: val_loss=1.0543\n",
            "Epoch 32: val_loss=1.2705\n",
            "Epoch 33: val_loss=1.0578\n",
            "Epoch 34: val_loss=1.1730\n",
            "Epoch 35: val_loss=1.1195\n",
            "Epoch 36: val_loss=1.0515\n",
            "Epoch 37: val_loss=1.0420\n",
            "Epoch 38: val_loss=1.0051\n",
            "Epoch 39: val_loss=1.1269\n",
            "Epoch 40: val_loss=1.0583\n",
            "Epoch 41: val_loss=0.9962\n",
            "Epoch 42: val_loss=1.0321\n",
            "Epoch 43: val_loss=1.3145\n",
            "Epoch 44: val_loss=1.0058\n",
            "Epoch 45: val_loss=1.1741\n",
            "Epoch 46: val_loss=1.0426\n",
            "Epoch 47: val_loss=1.0253\n",
            "Epoch 48: val_loss=0.9813\n",
            "Epoch 49: val_loss=0.9790\n",
            "Epoch 50: val_loss=1.0071\n",
            "Epoch 51: val_loss=1.0524\n",
            "Epoch 52: val_loss=0.9818\n",
            "Epoch 53: val_loss=0.9999\n",
            "Epoch 54: val_loss=1.0840\n",
            "Epoch 55: val_loss=0.9705\n",
            "Epoch 56: val_loss=1.0513\n",
            "Epoch 57: val_loss=1.1441\n",
            "Epoch 58: val_loss=0.9788\n",
            "Epoch 59: val_loss=1.2036\n",
            "Epoch 60: val_loss=0.9611\n",
            "Epoch 61: val_loss=1.0058\n",
            "Epoch 62: val_loss=1.0697\n",
            "Epoch 63: val_loss=1.0326\n",
            "Epoch 64: val_loss=0.9630\n",
            "Epoch 65: val_loss=0.9772\n",
            "Epoch 66: val_loss=0.9727\n",
            "Epoch 67: val_loss=0.9682\n",
            "Epoch 68: val_loss=0.9994\n",
            "Epoch 69: val_loss=1.0139\n",
            "Epoch 70: val_loss=0.9717\n",
            "Early stopping triggered.\n",
            "MAE : 0.7552, RMSE: 0.9810, R²: 0.3192\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1: val_loss=3.1797\n",
            "Epoch 2: val_loss=1.6280\n",
            "Epoch 3: val_loss=1.5165\n",
            "Epoch 4: val_loss=1.4537\n",
            "Epoch 5: val_loss=1.4300\n",
            "Epoch 6: val_loss=1.4081\n",
            "Epoch 7: val_loss=1.3884\n",
            "Epoch 8: val_loss=1.4010\n",
            "Epoch 9: val_loss=1.3560\n",
            "Epoch 10: val_loss=1.4023\n",
            "Epoch 11: val_loss=1.3356\n",
            "Epoch 12: val_loss=1.3425\n",
            "Epoch 13: val_loss=1.4020\n",
            "Epoch 14: val_loss=1.5380\n",
            "Epoch 15: val_loss=1.4717\n",
            "Epoch 16: val_loss=1.2778\n",
            "Epoch 17: val_loss=1.5297\n",
            "Epoch 18: val_loss=1.2349\n",
            "Epoch 19: val_loss=1.2303\n",
            "Epoch 20: val_loss=1.6034\n",
            "Epoch 21: val_loss=1.2042\n",
            "Epoch 22: val_loss=1.1926\n",
            "Epoch 23: val_loss=1.3445\n",
            "Epoch 24: val_loss=1.4908\n",
            "Epoch 25: val_loss=1.2165\n",
            "Epoch 26: val_loss=1.1536\n",
            "Epoch 27: val_loss=1.2469\n",
            "Epoch 28: val_loss=1.1708\n",
            "Epoch 29: val_loss=1.1519\n",
            "Epoch 30: val_loss=1.1898\n",
            "Epoch 31: val_loss=1.1357\n",
            "Epoch 32: val_loss=1.1780\n",
            "Epoch 33: val_loss=1.1258\n",
            "Epoch 34: val_loss=1.1330\n",
            "Epoch 35: val_loss=1.2573\n",
            "Epoch 36: val_loss=1.1084\n",
            "Epoch 37: val_loss=1.1355\n",
            "Epoch 38: val_loss=1.1081\n",
            "Epoch 39: val_loss=1.0920\n",
            "Epoch 40: val_loss=1.0911\n",
            "Epoch 41: val_loss=1.0841\n",
            "Epoch 42: val_loss=1.0811\n",
            "Epoch 43: val_loss=1.1164\n",
            "Epoch 44: val_loss=1.2091\n",
            "Epoch 45: val_loss=1.1137\n",
            "Epoch 46: val_loss=1.0752\n",
            "Epoch 47: val_loss=1.0393\n",
            "Epoch 48: val_loss=1.1088\n",
            "Epoch 49: val_loss=1.3333\n",
            "Epoch 50: val_loss=1.0632\n",
            "Epoch 51: val_loss=1.1910\n",
            "Epoch 52: val_loss=1.0578\n",
            "Epoch 53: val_loss=1.1066\n",
            "Epoch 54: val_loss=1.0526\n",
            "Epoch 55: val_loss=1.0785\n",
            "Epoch 56: val_loss=1.1589\n",
            "Epoch 57: val_loss=1.0998\n",
            "Early stopping triggered.\n",
            "MAE : 0.8147, RMSE: 1.0538, R²: 0.2932\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1: val_loss=3.2301\n",
            "Epoch 2: val_loss=1.5684\n",
            "Epoch 3: val_loss=1.5170\n",
            "Epoch 4: val_loss=1.5090\n",
            "Epoch 5: val_loss=1.4576\n",
            "Epoch 6: val_loss=1.4369\n",
            "Epoch 7: val_loss=1.4058\n",
            "Epoch 8: val_loss=1.3736\n",
            "Epoch 9: val_loss=1.3484\n",
            "Epoch 10: val_loss=1.4840\n",
            "Epoch 11: val_loss=1.4049\n",
            "Epoch 12: val_loss=1.2848\n",
            "Epoch 13: val_loss=1.2795\n",
            "Epoch 14: val_loss=1.2399\n",
            "Epoch 15: val_loss=1.2202\n",
            "Epoch 16: val_loss=1.2934\n",
            "Epoch 17: val_loss=1.2239\n",
            "Epoch 18: val_loss=1.4478\n",
            "Epoch 19: val_loss=1.2827\n",
            "Epoch 20: val_loss=1.2412\n",
            "Epoch 21: val_loss=1.1703\n",
            "Epoch 22: val_loss=1.1529\n",
            "Epoch 23: val_loss=1.2538\n",
            "Epoch 24: val_loss=1.2093\n",
            "Epoch 25: val_loss=1.1436\n",
            "Epoch 26: val_loss=1.3687\n",
            "Epoch 27: val_loss=1.1506\n",
            "Epoch 28: val_loss=1.2059\n",
            "Epoch 29: val_loss=1.1594\n",
            "Epoch 30: val_loss=1.1374\n",
            "Epoch 31: val_loss=1.1132\n",
            "Epoch 32: val_loss=1.2121\n",
            "Epoch 33: val_loss=1.5338\n",
            "Epoch 34: val_loss=1.1528\n",
            "Epoch 35: val_loss=1.1174\n",
            "Epoch 36: val_loss=1.1704\n",
            "Epoch 37: val_loss=1.1206\n",
            "Epoch 38: val_loss=1.0890\n",
            "Epoch 39: val_loss=1.1222\n",
            "Epoch 40: val_loss=1.1149\n",
            "Epoch 41: val_loss=1.1913\n",
            "Epoch 42: val_loss=1.1323\n",
            "Epoch 43: val_loss=1.1188\n",
            "Epoch 44: val_loss=1.1174\n",
            "Epoch 45: val_loss=1.7204\n",
            "Epoch 46: val_loss=1.1383\n",
            "Epoch 47: val_loss=1.1179\n",
            "Epoch 48: val_loss=1.2029\n",
            "Early stopping triggered.\n",
            "MAE : 0.8340, RMSE: 1.0977, R²: 0.2522\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1: val_loss=4.7312\n",
            "Epoch 2: val_loss=1.5635\n",
            "Epoch 3: val_loss=1.4995\n",
            "Epoch 4: val_loss=1.4798\n",
            "Epoch 5: val_loss=1.5357\n",
            "Epoch 6: val_loss=1.4728\n",
            "Epoch 7: val_loss=1.4342\n",
            "Epoch 8: val_loss=1.4063\n",
            "Epoch 9: val_loss=1.3849\n",
            "Epoch 10: val_loss=1.3522\n",
            "Epoch 11: val_loss=1.3483\n",
            "Epoch 12: val_loss=1.3575\n",
            "Epoch 13: val_loss=1.3069\n",
            "Epoch 14: val_loss=1.3515\n",
            "Epoch 15: val_loss=1.2989\n",
            "Epoch 16: val_loss=1.3466\n",
            "Epoch 17: val_loss=1.3370\n",
            "Epoch 18: val_loss=1.3177\n",
            "Epoch 19: val_loss=1.2698\n",
            "Epoch 20: val_loss=1.3090\n",
            "Epoch 21: val_loss=1.3275\n",
            "Epoch 22: val_loss=1.2205\n",
            "Epoch 23: val_loss=1.3592\n",
            "Epoch 24: val_loss=1.2538\n",
            "Epoch 25: val_loss=1.1907\n",
            "Epoch 26: val_loss=1.1854\n",
            "Epoch 27: val_loss=1.1973\n",
            "Epoch 28: val_loss=1.2264\n",
            "Epoch 29: val_loss=1.2355\n",
            "Epoch 30: val_loss=1.4386\n",
            "Epoch 31: val_loss=1.5852\n",
            "Epoch 32: val_loss=1.1611\n",
            "Epoch 33: val_loss=1.1789\n",
            "Epoch 34: val_loss=1.1658\n",
            "Epoch 35: val_loss=1.1887\n",
            "Epoch 36: val_loss=1.3371\n",
            "Epoch 37: val_loss=1.2011\n",
            "Epoch 38: val_loss=1.2458\n",
            "Epoch 39: val_loss=1.2918\n",
            "Epoch 40: val_loss=1.1323\n",
            "Epoch 41: val_loss=1.1879\n",
            "Epoch 42: val_loss=1.1670\n",
            "Epoch 43: val_loss=1.1403\n",
            "Epoch 44: val_loss=1.1454\n",
            "Epoch 45: val_loss=1.4541\n",
            "Epoch 46: val_loss=1.1703\n",
            "Epoch 47: val_loss=1.1902\n",
            "Epoch 48: val_loss=1.1939\n",
            "Epoch 49: val_loss=1.1287\n",
            "Epoch 50: val_loss=1.2206\n",
            "Epoch 51: val_loss=1.1294\n",
            "Epoch 52: val_loss=1.1823\n",
            "Epoch 53: val_loss=1.1425\n",
            "Epoch 54: val_loss=1.1957\n",
            "Epoch 55: val_loss=1.1803\n",
            "Epoch 56: val_loss=1.1472\n",
            "Epoch 57: val_loss=1.1305\n",
            "Epoch 58: val_loss=1.1935\n",
            "Epoch 59: val_loss=1.1315\n",
            "Early stopping triggered.\n",
            "MAE : 0.7996, RMSE: 1.0320, R²: 0.3162\n",
            "\n",
            "=== Метрики на кросс-валидации ===\n",
            "MAE : 0.8087 ± 0.0304\n",
            "RMSE: 1.0638 ± 0.0589\n",
            "R²  : 0.2630 ± 0.0687\n",
            "\n",
            "=== Финальное обучение на train+val ===\n",
            "Final model saved to final_cnn_model.pth\n",
            "\n",
            "=== Загрузка модели и тестирование ===\n",
            "Test MAE : 0.7704\n",
            "Test RMSE: 1.0412\n",
            "Test R²  : 0.3208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLr2HwIVKDLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
